<!-- AGENT INSTRUCTIONS (не включать в итоговый текст)
Контекст: Курсовая работа на факультете биоинформатики
Формат вывода: 
- НЕ использовать markdown форматирование (жирный, курсив) — текст копируется в Google Docs
- Писать в научном стиле с DOI-ссылками в формате [Author et al., Year; doi:...]
- Нумерация разделов должна соответствовать структуре ниже (5.1, 5.2, ...)
-->

# План

## Материалы и методы

### 1. Подготовка данных
**1.1 Исходный датасет и фильтрация**
- Источник: ASD (NaturalAntibody), ~X записей
- Критерии фильтрации:
  - Удалены записи с `confidence = medium`
  - Удалены nanobody (только парные VH+VL)
  - Удалены записи с пустыми последовательностями
  - scFv: разделение на VH/VL (если применимо)
- Результат: было → стало (с оговоркой о динамичности датасета)


**1.2 Бинаризация аффиности**
- Распределение binder/non-binder после бинаризации
- Валидация порогов на пересекающихся измерениях


**1.3 Дедупликация**
- уникальные VH+VL + последовательность антигена
- Финальный размер датасета


**1.4 Разбиение на train/val/test**
- Стратегия разбиения (по антигенам? случайно?)
- Размеры выборок
- Проверка на утечку данных (если разбиение по антигенам)

? Антиген только с UniProt/PDB
если нужна строгая идентификация таргета: оставлять записи с metadata.target_uniprot или metadata.target_pdb.
? Исключение “доминирующих” антигенов (bias control)
на сайте прямо отмечено, что в статистике они не учитывают HER2 из-за огромной доли, и отдельно упоминают патенты (умеренная уверенность). Это полезный сигнал, что в реальных выборках HER2 может “перекосить” обучение/метрики.

---


### 2. Модель и обучение
**2.1 Базовая модель p-IgGen**
- Архитектура (GPT-2, размер)
- Формат входа: `[ANTIGEN] ... [SEP] [VH] ... [VL] ...`
- Предобученные веса


**2.2 Стратегия дообучения**
- Выбор PEFT-метода (prefix-tuning / adapters)
- Гиперпараметры (lr, batch size, epochs)
- Обоснование выбора (catastrophic forgetting, вычислительные ресурсы)


**2.3 Процесс обучения**
- Кривые loss (train/val)
- Ранняя остановка / выбор чекпоинта
- Время/ресурсы обучения


---


### 3. Оценка качества генерации
**3.1 Метрики языковой модели**
- Perplexity на test set
- Сравнение с baseline (до дообучения)


**3.2 Качество последовательностей**
- AAR (Amino Acid Recovery) — если есть ground truth
- Валидность: % последовательностей, проходящих ANARCI-нумерацию
- Распределение длин CDR


**3.3 Разнообразие и новизна**
- Diversity: внутрикластерное расстояние (Levenshtein / embedding)
- Novelty: расстояние до ближайшего в train set
- t-SNE/UMAP визуализация


**3.4 Структурная валидация (опционально)**
- pLDDT предсказанных структур (AF3/ESMFold)
- Сравнение с реальными структурами (если есть)


---


### 4. Сравнение с бейзлайнами
**4.1 Antigen-agnostic baseline**
- p-IgGen без условия на антиген
- Сравнение метрик: насколько хуже "слепая" генерация?


**4.2 Nearest-neighbor baseline**
- Поиск ближайшего антигена в train → возврат известных антител
- Сравнение: генерация vs retrieval


**4.3 (Опционально) Сравнение со структурными методами**
- DiffAb / RFantibody на том же test set
- Компромисс: качество vs вычислительные затраты





# Материалы и методы
Фильтрация датасета
убрали medium по confidence
убрали nanobody
убрали пустые посл-ти (кроме scfv, их разделить еще (ANARCI))
разметили binder/non-binder (пороги выше)

