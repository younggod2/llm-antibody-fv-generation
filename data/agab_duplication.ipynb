{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bd9d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9650f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 20 parquet файлов\n",
      "Общий размер данных: (1227083, 11)\n",
      "Колонки: ['dataset', 'heavy_sequence', 'light_sequence', 'scfv', 'affinity_type', 'affinity', 'antigen_sequence', 'confidence', 'nanobody', 'metadata', 'processed_measurement']\n"
     ]
    }
   ],
   "source": [
    "def load_asd_data_with_pandas(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает все parquet файлы из папки asd в один pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        data_path: путь к папке с данными\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: объединенный DataFrame со всеми данными\n",
    "    \"\"\"\n",
    "    # Получаем все parquet файлы из папки\n",
    "    parquet_files = glob.glob(os.path.join(data_path, \"part-*.parquet\"))\n",
    "\n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"Не найдено parquet файлов в папке {data_path}\")\n",
    "\n",
    "    print(f\"Найдено {len(parquet_files)} parquet файлов\")\n",
    "\n",
    "    # Загружаем все файлы в список DataFrame'ов\n",
    "    dataframes = []\n",
    "    for file_path in parquet_files:\n",
    "        # print(f\"Загружаем файл: {os.path.basename(file_path)}\")\n",
    "        df = pd.read_parquet(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Объединяем все DataFrame'ы в один\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    print(f\"Общий размер данных: {combined_df.shape}\")\n",
    "    print(f\"Колонки: {list(combined_df.columns)}\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Загружаем данные\n",
    "agab_df = load_asd_data_with_pandas('./asd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ff1b4",
   "metadata": {},
   "source": [
    "### По файлам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc456a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ ДУБЛИКАТОВ ПО ФАЙЛАМ ===\n",
      "\n",
      "Дубликаты внутри каждого файла:\n",
      "                                                               file  rows  duplicates  duplicate_pct\n",
      "part-00000-3a065afd-b2fa-4875-a6e5-911e95e3f86c-c000.snappy.parquet 61329        2777       4.528037\n",
      "part-00001-74fdee0d-8448-4b0a-921c-f1f0ef356cdf-c000.snappy.parquet 60919        2740       4.497776\n",
      "part-00002-634ededa-5adf-4170-93ba-2dac2bd74705-c000.snappy.parquet 63736        2550       4.000879\n",
      "part-00003-427bc79e-0e40-4a8c-a2be-d0fbe09f03c0-c000.snappy.parquet 61152        2542       4.156855\n",
      "part-00004-eb3dc336-995c-48bd-840f-49d411a89b8e-c000.snappy.parquet 60125        2936       4.883160\n",
      "part-00005-846a5164-9ca8-4438-af5f-07ad5348f327-c000.snappy.parquet 61104        2816       4.608536\n",
      "part-00006-b818506c-2926-406c-936b-66da5c9acdbc-c000.snappy.parquet 62158        3105       4.995334\n",
      "part-00007-7ab8e466-84f8-43e0-8874-9c1bbf210d4e-c000.snappy.parquet 60256        2778       4.610329\n",
      "part-00008-397aa529-5cb9-4e24-8898-c9940200ae64-c000.snappy.parquet 60278        2860       4.744683\n",
      "part-00009-6b319ece-d8eb-4e15-b579-4e98d3a456a1-c000.snappy.parquet 60758        2858       4.703907\n",
      "part-00010-7edd7ab3-f323-4718-a2ac-138fb65b3f42-c000.snappy.parquet 62283        2811       4.513270\n",
      "part-00011-86ada209-259a-4a93-8a61-ee6555e0f25d-c000.snappy.parquet 61004        2713       4.447249\n",
      "part-00012-fe431735-b7e1-4367-b665-15a59e7bd12c-c000.snappy.parquet 59117        2893       4.893685\n",
      "part-00013-26624da0-a286-49c6-98c5-c019816424b8-c000.snappy.parquet 61156        2738       4.477075\n",
      "part-00014-0bbd5d34-4a5c-4c7f-9c69-ba69e33861b1-c000.snappy.parquet 61704        3064       4.965642\n",
      "part-00015-af04209c-672a-4fd7-9cc5-1fdaeaf06aa0-c000.snappy.parquet 62936        2980       4.734969\n",
      "part-00016-883dd12e-3f06-4505-b326-04b6c16a7852-c000.snappy.parquet 62627        2804       4.477302\n",
      "part-00017-b88913fa-e655-4662-8208-45e9f4d38488-c000.snappy.parquet 61052        2785       4.561685\n",
      "part-00018-630653e8-04e5-4d69-bd4f-96225f04fb82-c000.snappy.parquet 61479        2896       4.710552\n",
      "part-00019-2a17653c-3a60-4f9a-b840-e7b168d3d6f9-c000.snappy.parquet 61910        2790       4.506542\n",
      "\n",
      "Общее количество дубликатов внутри файлов: 56436\n"
     ]
    }
   ],
   "source": [
    "print('дубль — одинаковы все колонки, кроме metadata\\n')\n",
    "print(\"=== АНАЛИЗ ДУБЛИКАТОВ ПО ФАЙЛАМ ===\\n\")\n",
    "\n",
    "parquet_files = glob.glob(os.path.join('./asd', \"part-*.parquet\"))\n",
    "parquet_files.sort()\n",
    "\n",
    "file_duplicates = []\n",
    "for file_path in parquet_files:\n",
    "    df = pd.read_parquet(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    duplicates_in_file = df.drop(columns=['metadata']).duplicated().sum()\n",
    "    file_duplicates.append({\n",
    "        'file': file_name,\n",
    "        'rows': len(df),\n",
    "        'duplicates': duplicates_in_file,\n",
    "        'duplicate_pct': duplicates_in_file / len(df) * 100 if len(df) > 0 else 0\n",
    "    })\n",
    "\n",
    "file_duplicates_df = pd.DataFrame(file_duplicates)\n",
    "print(\"Дубликаты внутри каждого файла:\")\n",
    "print(file_duplicates_df.to_string(index=False))\n",
    "print(f\"\\nОбщее количество дубликатов внутри файлов: {file_duplicates_df['duplicates'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d319ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== АНАЛИЗ ПЕРЕКРЫТИЙ МЕЖДУ ФАЙЛАМИ ===\n",
      "\n",
      "Перекрытий между файлами не обнаружено.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== АНАЛИЗ ПЕРЕКРЫТИЙ МЕЖДУ ФАЙЛАМИ ===\\n\")\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "file_unique_sets = {os.path.basename(fp): set(pd.read_parquet(fp).drop(columns=['metadata']).apply(tuple, axis=1)) for fp in parquet_files}\n",
    "\n",
    "overlaps = [{'file1': f1, 'file2': f2, 'overlap_count': overlap, 'file1_size': len(s1), 'file2_size': len(s2), \n",
    "             'overlap_pct_file1': overlap / len(s1) * 100 if len(s1) > 0 else 0, 'overlap_pct_file2': overlap / len(s2) * 100 if len(s2) > 0 else 0}\n",
    "            for (f1, s1), (f2, s2) in combinations(file_unique_sets.items(), 2) if (overlap := len(s1 & s2)) > 0]\n",
    "\n",
    "if overlaps:\n",
    "    overlaps_df = pd.DataFrame(overlaps)\n",
    "    print(\"Найдены перекрытия между файлами:\")\n",
    "    print(overlaps_df.to_string(index=False))\n",
    "    print(f\"\\nВсего пар файлов с перекрытиями: {len(overlaps)}\")\n",
    "    print(f\"Общее количество перекрывающихся записей: {overlaps_df['overlap_count'].sum()}\")\n",
    "else:\n",
    "    print(\"Перекрытий между файлами не обнаружено.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b05fdd",
   "metadata": {},
   "source": [
    "### По датасетам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76ec759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дубль — одинаковы все колонки, кроме metadata\n",
      "\n",
      "\n",
      "=== АНАЛИЗ ДУБЛИКАТОВ ПО ДАТАСЕТАМ ===\n",
      "\n",
      "Дубликаты по датасетам:\n",
      "                dataset  total_rows  duplicates  duplicate_pct  unique_rows\n",
      "               covid-19       54625       27482      50.310297        27143\n",
      "                    hiv       48008       24715      51.481003        23293\n",
      "                 biomap        2725        1402      51.449541         1323\n",
      "  structures-antibodies        2711        1170      43.157506         1541\n",
      "                genbank        2989         717      23.987956         2272\n",
      "  structures-nanobodies        1258         649      51.589825          609\n",
      "                patents      217463         164       0.075415       217299\n",
      "                   abbd      155853         132       0.084695       155721\n",
      "               alphaseq      198703           4       0.002013       198699\n",
      "flab_shanehsazzadeh2023         446           1       0.224215          445\n",
      "               abdesign         672           0       0.000000          672\n",
      "        flab_koenig2017        4275           0       0.000000         4275\n",
      "                    met        4000           0       0.000000         4000\n",
      "        flab_rosace2023          25           0       0.000000           25\n",
      "           flab_hie2022          55           0       0.000000           55\n",
      "                   aatp          93           0       0.000000           93\n",
      "    flab_warszawski2019        2048           0       0.000000         2048\n",
      "                ab-bind         283           0       0.000000          283\n",
      "                   rmna          10           0       0.000000           10\n",
      "                    aae          35           0       0.000000           35\n",
      "                   buzz      524346           0       0.000000       524346\n",
      "                    osh          30           0       0.000000           30\n",
      "                   dlgo         360           0       0.000000          360\n",
      "               skempiv2         434           0       0.000000          434\n",
      "             literature        5636           0       0.000000         5636\n"
     ]
    }
   ],
   "source": [
    "print('дубль — одинаковы все колонки, кроме metadata\\n')\n",
    "print(\"\\n=== АНАЛИЗ ДУБЛИКАТОВ ПО ДАТАСЕТАМ ===\\n\")\n",
    "\n",
    "dataset_analysis = []\n",
    "for dataset in agab_df['dataset'].unique():\n",
    "    dataset_df = agab_df[agab_df['dataset'] == dataset]\n",
    "    duplicates = dataset_df.drop(columns=['metadata']).duplicated().sum()\n",
    "    dataset_analysis.append({\n",
    "        'dataset': dataset,\n",
    "        'total_rows': len(dataset_df),\n",
    "        'duplicates': duplicates,\n",
    "        'duplicate_pct': duplicates / len(dataset_df) * 100 if len(dataset_df) > 0 else 0,\n",
    "        'unique_rows': len(dataset_df) - duplicates\n",
    "    })\n",
    "\n",
    "dataset_analysis_df = pd.DataFrame(dataset_analysis).sort_values('duplicates', ascending=False)\n",
    "print(\"Дубликаты по датасетам:\")\n",
    "print(dataset_analysis_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c05070d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дубль — одинаковы все колонки\n",
      "\n",
      "\n",
      "=== АНАЛИЗ ДУБЛИКАТОВ ПО ДАТАСЕТАМ ===\n",
      "\n",
      "\n",
      "Топdataset по количеству дубликатов:\n",
      "                dataset  total_rows  duplicates_count  duplicates_ratio\n",
      "                    hiv       48008             24715            0.5148\n",
      "                 biomap        2725              1402            0.5145\n",
      "  structures-antibodies        2711               999            0.3685\n",
      "  structures-nanobodies        1258               566            0.4499\n",
      "                genbank        2989               480            0.1606\n",
      "               covid-19       54625               303            0.0055\n",
      "                   abbd      155853               132            0.0008\n",
      "               alphaseq      198703                 4            0.0000\n",
      "flab_shanehsazzadeh2023         446                 1            0.0022\n",
      "               skempiv2         434                 0            0.0000\n",
      "                   rmna          10                 0            0.0000\n",
      "                patents      217463                 0            0.0000\n",
      "                    osh          30                 0            0.0000\n",
      "                    met        4000                 0            0.0000\n",
      "             literature        5636                 0            0.0000\n",
      "                    aae          35                 0            0.0000\n",
      "    flab_warszawski2019        2048                 0            0.0000\n",
      "                   aatp          93                 0            0.0000\n",
      "        flab_koenig2017        4275                 0            0.0000\n",
      "           flab_hie2022          55                 0            0.0000\n",
      "                   dlgo         360                 0            0.0000\n",
      "                   buzz      524346                 0            0.0000\n",
      "               abdesign         672                 0            0.0000\n",
      "                ab-bind         283                 0            0.0000\n",
      "        flab_rosace2023          25                 0            0.0000\n",
      "\n",
      "Всего dataset: 25\n",
      "Dataset с дубликатами: 9\n",
      "Dataset без дубликатов: 16\n"
     ]
    }
   ],
   "source": [
    "print('дубль — одинаковы все колонки\\n')\n",
    "print(\"\\n=== АНАЛИЗ ДУБЛИКАТОВ ПО ДАТАСЕТАМ ===\\n\")\n",
    "\n",
    "# Добавляем флаг дубликатов в исходный DataFrame\n",
    "agab_df['is_duplicate'] = duplicates_with_metadata_mask\n",
    "\n",
    "# Группируем по dataset и считаем статистику\n",
    "dataset_duplicates = agab_df.groupby('dataset').agg({\n",
    "    'is_duplicate': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "# Переименовываем столбцы для удобства\n",
    "dataset_duplicates.columns = ['total_rows', 'duplicates_count', 'duplicates_ratio']\n",
    "dataset_duplicates = dataset_duplicates.reset_index()\n",
    "\n",
    "# Сортируем по количеству дубликатов\n",
    "dataset_duplicates = dataset_duplicates.sort_values('duplicates_count', ascending=False)\n",
    "\n",
    "print(\"\\nТопdataset по количеству дубликатов:\")\n",
    "print(dataset_duplicates.to_string(index=False))\n",
    "\n",
    "# Общая статистика по распределению\n",
    "print(f\"\\nВсего dataset: {len(dataset_duplicates)}\")\n",
    "print(f\"Dataset с дубликатами: {len(dataset_duplicates[dataset_duplicates['duplicates_count'] > 0])}\")\n",
    "print(f\"Dataset без дубликатов: {len(dataset_duplicates[dataset_duplicates['duplicates_count'] == 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a270366",
   "metadata": {},
   "source": [
    "### Cтатистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15afe93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Статистика дубликатов ===\n",
      "Всего строк: 1227083\n",
      "Дубликатов: 56436\n",
      "Уникальных строк: 1170647\n",
      "\n",
      "=== Дубликаты с учетом metadata ===\n",
      "Дубликатов с учетом metadata: 28602\n",
      "Уникальных строк с учетом metadata: 1198481\n",
      "\n",
      "=== Сравнительная статистика ===\n",
      "Разница в количестве дубликатов: 27834\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Статистика дубликатов ===\")\n",
    "print(f\"Всего строк: {len(agab_df)}\")\n",
    "\n",
    "# Создаем маску дубликатов один раз для эффективности\n",
    "duplicates_mask = agab_df.drop(columns='metadata').duplicated()\n",
    "duplicates_count = duplicates_mask.sum()\n",
    "\n",
    "print(f\"Дубликатов: {duplicates_count}\")\n",
    "print(f\"Уникальных строк: {len(agab_df) - duplicates_count}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Дубликаты с учетом metadata ===\")\n",
    "\n",
    "# Создаем временный DataFrame, преобразуя metadata в строку JSON\n",
    "temp_df = agab_df.copy()\n",
    "temp_df['metadata_json'] = temp_df['metadata'].apply(lambda x: json.dumps(x, sort_keys=True) if isinstance(x, dict) else str(x))\n",
    "\n",
    "# Проверяем дубликаты, исключая столбец metadata (используем все столбцы кроме metadata)\n",
    "columns_to_check = [col for col in temp_df.columns if col != 'metadata']\n",
    "duplicates_with_metadata_mask = temp_df[columns_to_check].duplicated()\n",
    "duplicates_with_metadata_count = duplicates_with_metadata_mask.sum()\n",
    "\n",
    "print(f\"Дубликатов с учетом metadata: {duplicates_with_metadata_count}\")\n",
    "print(f\"Уникальных строк с учетом metadata: {len(agab_df) - duplicates_with_metadata_count}\")\n",
    "\n",
    "print(\"\\n=== Сравнительная статистика ===\")\n",
    "print(f\"Разница в количестве дубликатов: {duplicates_count - duplicates_with_metadata_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62c083",
   "metadata": {},
   "source": [
    "### Различия metadata в дублях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79073bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на примере covid-19\n",
    "covid_df = agab_df[\n",
    "    (agab_df['dataset'] == 'covid-19')\n",
    "    & (agab_df['scfv'] == False)\n",
    "    & (agab_df['nanobody'] == False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b13f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ РАЗЛИЧИЙ В METADATA МЕЖДУ ДУБЛИКАТАМИ В COVID-19 ===\n",
      "\n",
      "Всего групп дубликатов: 27142\n",
      "\n",
      "Проанализировано групп: 27142\n",
      "Групп с одинаковым metadata: 0 (0.00%)\n",
      "Групп с различиями в metadata: 27142 (100.00%)\n",
      "\n",
      "=== ПОЛЯ METADATA, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m field_differences:\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== ПОЛЯ METADATA, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m field, count \u001b[38;5;129;01min\u001b[39;00m field_differences:\n\u001b[32m     92\u001b[39m         pct = count / groups_with_differences * \u001b[32m100\u001b[39m\n\u001b[32m     93\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m групп (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpct\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% от групп с различиями)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "print(\"=== АНАЛИЗ РАЗЛИЧИЙ В METADATA МЕЖДУ ДУБЛИКАТАМИ В COVID-19 ===\\n\")\n",
    "\n",
    "# Находим дубликаты в covid_df по всем колонкам кроме metadata\n",
    "covid_duplicates_mask = covid_df.drop(columns=['metadata']).duplicated(keep=False)\n",
    "covid_duplicates = covid_df[covid_duplicates_mask].copy()\n",
    "\n",
    "# Создаем ключ для группировки\n",
    "covid_duplicates['duplicate_key'] = covid_duplicates.drop(columns=['metadata']).apply(tuple, axis=1)\n",
    "\n",
    "# Получаем уникальные группы дубликатов\n",
    "unique_duplicate_groups = covid_duplicates['duplicate_key'].unique()\n",
    "\n",
    "print(f\"Всего групп дубликатов: {len(unique_duplicate_groups)}\\n\")\n",
    "\n",
    "# Функция для рекурсивного сравнения словарей и поиска различий\n",
    "def find_different_keys(dict1, dict2, path=\"\"):\n",
    "    \"\"\"Находит все ключи, которые различаются между двумя словарями\"\"\"\n",
    "    different_keys = set()\n",
    "    \n",
    "    if not isinstance(dict1, dict) or not isinstance(dict2, dict):\n",
    "        if dict1 != dict2:\n",
    "            return {path} if path else set()\n",
    "        return set()\n",
    "    \n",
    "    all_keys = set(dict1.keys()) | set(dict2.keys())\n",
    "    \n",
    "    for key in all_keys:\n",
    "        current_path = f\"{path}.{key}\" if path else key\n",
    "        val1 = dict1.get(key)\n",
    "        val2 = dict2.get(key)\n",
    "        \n",
    "        if key not in dict1:\n",
    "            different_keys.add(current_path)\n",
    "        elif key not in dict2:\n",
    "            different_keys.add(current_path)\n",
    "        elif isinstance(val1, dict) and isinstance(val2, dict):\n",
    "            different_keys.update(find_different_keys(val1, val2, current_path))\n",
    "        elif val1 != val2:\n",
    "            different_keys.add(current_path)\n",
    "    \n",
    "    return different_keys\n",
    "\n",
    "# Собираем статистику по различиям\n",
    "field_differences = Counter()\n",
    "groups_with_differences = 0\n",
    "groups_with_same_metadata = 0\n",
    "total_groups_analyzed = 0\n",
    "\n",
    "# Анализируем каждую группу дубликатов\n",
    "for group_key in unique_duplicate_groups:\n",
    "    group_data = covid_duplicates[covid_duplicates['duplicate_key'] == group_key]\n",
    "    \n",
    "    if len(group_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    total_groups_analyzed += 1\n",
    "    \n",
    "    # Сравниваем metadata между всеми парами в группе\n",
    "    metadata_list = group_data['metadata'].tolist()\n",
    "    \n",
    "    # Проверяем, все ли metadata одинаковые\n",
    "    all_same = True\n",
    "    group_differences = set()\n",
    "    \n",
    "    for i in range(len(metadata_list)):\n",
    "        for j in range(i + 1, len(metadata_list)):\n",
    "            meta1 = metadata_list[i] if isinstance(metadata_list[i], dict) else {}\n",
    "            meta2 = metadata_list[j] if isinstance(metadata_list[j], dict) else {}\n",
    "            \n",
    "            diff_keys = find_different_keys(meta1, meta2)\n",
    "            if diff_keys:\n",
    "                all_same = False\n",
    "                group_differences.update(diff_keys)\n",
    "    \n",
    "    if all_same:\n",
    "        groups_with_same_metadata += 1\n",
    "    else:\n",
    "        groups_with_differences += 1\n",
    "        for key in group_differences:\n",
    "            field_differences[key] += 1\n",
    "\n",
    "print(f\"Проанализировано групп: {total_groups_analyzed}\")\n",
    "print(f\"Групп с одинаковым metadata: {groups_with_same_metadata} ({groups_with_same_metadata/total_groups_analyzed*100:.2f}%)\")\n",
    "print(f\"Групп с различиями в metadata: {groups_with_differences} ({groups_with_differences/total_groups_analyzed*100:.2f}%)\\n\")\n",
    "\n",
    "if field_differences:\n",
    "    print(\"=== ПОЛЯ METADATA, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\\n\")\n",
    "    for field, count in field_differences:\n",
    "        pct = count / groups_with_differences * 100\n",
    "        print(f\"{field}: {count} групп ({pct:.2f}% от групп с различиями)\")\n",
    "    \n",
    "    print(f\"\\nВсего уникальных полей с различиями: {len(field_differences)}\")\n",
    "else:\n",
    "    print(\"Различий в metadata между дубликатами не найдено.\")\n",
    "\n",
    "# Показываем примеры групп с различиями\n",
    "print(\"\\n=== ПРИМЕРЫ ГРУПП С РАЗЛИЧИЯМИ В METADATA ===\\n\")\n",
    "\n",
    "examples_shown = 0\n",
    "for group_key in unique_duplicate_groups:\n",
    "    if examples_shown >= 5:\n",
    "        break\n",
    "    \n",
    "    group_data = covid_duplicates[covid_duplicates['duplicate_key'] == group_key].copy()\n",
    "    \n",
    "    if len(group_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    metadata_list = group_data['metadata'].tolist()\n",
    "    \n",
    "    # Проверяем, есть ли различия\n",
    "    has_differences = False\n",
    "    all_differences = set()\n",
    "    \n",
    "    for i in range(len(metadata_list)):\n",
    "        for j in range(i + 1, len(metadata_list)):\n",
    "            meta1 = metadata_list[i] if isinstance(metadata_list[i], dict) else {}\n",
    "            meta2 = metadata_list[j] if isinstance(metadata_list[j], dict) else {}\n",
    "            \n",
    "            diff_keys = find_different_keys(meta1, meta2)\n",
    "            if diff_keys:\n",
    "                has_differences = True\n",
    "                all_differences.update(diff_keys)\n",
    "    \n",
    "    if has_differences:\n",
    "        examples_shown += 1\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Пример {examples_shown}: Группа из {len(group_data)} дубликатов\")\n",
    "        print(f\"Различающиеся поля: {', '.join(sorted(all_differences))}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Показываем первые 2 записи из группы\n",
    "        for idx, (row_idx, row) in enumerate(group_data.head(2).iterrows()):\n",
    "            print(f\"--- Запись {idx+1} (индекс {row_idx}) ---\")\n",
    "            metadata_str = json.dumps(row['metadata'], indent=2, ensure_ascii=False) if isinstance(row['metadata'], dict) else str(row['metadata'])\n",
    "            print(f\"metadata:\\n{metadata_str}\\n\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Удаляем временную колонку\n",
    "covid_duplicates.drop(columns=['duplicate_key'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e394c95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 55265:\n",
      " {\n",
      "  \"target_name\": null,\n",
      "  \"target_pdb\": \"\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://academic.oup.com/bib/article/26/1/bbaf008/7964432\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFTFTSSA\",\n",
      "    \"cdr2_aa\": \"IVVGSGNT\",\n",
      "    \"cdr3_aa\": \"AAPYCSGGSCFDGFDI\",\n",
      "    \"sequence_alignment_aa\": \"QMQLVQSGPEVKKPGTSVKVSCKASGFTFTSSAVQWVRQARGQRLEWIGWIVVGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSGGSCFDGFDIWGQGTMVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "} \n",
      "\n",
      "Индекс 55266:\n",
      " {\n",
      "  \"target_name\": \"sars-cov2_omicron\",\n",
      "  \"target_pdb\": \"\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://academic.oup.com/bioinformatics/article/37/5/734/5893556\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFTFTSSA\",\n",
      "    \"cdr2_aa\": \"IVVGSGNT\",\n",
      "    \"cdr3_aa\": \"AAPYCSGGSCFDGFDI\",\n",
      "    \"sequence_alignment_aa\": \"QMQLVQSGPEVKKPGTSVKVSCKASGFTFTSSAVQWVRQARGQRLEWIGWIVVGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSGGSCFDGFDIWGQGTMVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# они друг за другом идут в covid-19\n",
    "for idx, meta in covid_df.iloc[1000:1002]['metadata'].items():\n",
    "    print(f'Индекс {idx}:\\n', json.dumps(meta, ensure_ascii=False, indent=2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1298bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ РАЗЛИЧИЙ В METADATA МЕЖДУ ДУБЛИКАТАМИ В AGAB ===\n",
      "\n",
      "Всего групп дубликатов: 53478\n",
      "\n",
      "Проанализировано групп: 53478\n",
      "Групп с одинаковым metadata: 25872 (48.38%)\n",
      "Групп с различиями в metadata: 27606 (51.62%)\n",
      "\n",
      "=== ТОП-20 ПОЛЕЙ METADATA, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\n",
      "\n",
      "target_name: 27433 групп (99.37% от групп с различиями)\n",
      "source_url: 27142 групп (98.32% от групп с различиями)\n",
      "target_uniprot: 225 групп (0.82% от групп с различиями)\n",
      "target_pdb: 133 групп (0.48% от групп с различиями)\n",
      "\n",
      "Всего уникальных полей с различиями: 4\n",
      "\n",
      "=== ПРИМЕРЫ ГРУПП С РАЗЛИЧИЯМИ В METADATA ===\n",
      "\n",
      "================================================================================\n",
      "Пример 1: Группа из 4 дубликатов\n",
      "Различающиеся поля: target_pdb\n",
      "================================================================================\n",
      "\n",
      "--- Запись 1 (индекс 33) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: EVQLLESGGGLVQPGGSLRLSCAASGFRFDAEDMGWVRQAPGKGLEWVSSIYGPSGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKYTSPPQNHGFDYWGQGTLVTVSS\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"4u3x\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFRFDAED\",\n",
      "    \"cdr2_aa\": \"IYGPSGST\",\n",
      "    \"cdr3_aa\": \"AKYTSPPQNHGFDY\",\n",
      "    \"sequence_alignment_aa\": \"EVQLLESGGGLVQPGGSLRLSCAASGFRFDAEDMGWVRQAPGKGLEWVSSIYGPSGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKYTSPPQNHGFDYWGQGTLVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "--- Запись 2 (индекс 34) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: EVQLLESGGGLVQPGGSLRLSCAASGFRFDAEDMGWVRQAPGKGLEWVSSIYGPSGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKYTSPPQNHGFDYWGQGTLVTVSS\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"4u3x\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFRFDAED\",\n",
      "    \"cdr2_aa\": \"IYGPSGST\",\n",
      "    \"cdr3_aa\": \"AKYTSPPQNHGFDY\",\n",
      "    \"sequence_alignment_aa\": \"EVQLLESGGGLVQPGGSLRLSCAASGFRFDAEDMGWVRQAPGKGLEWVSSIYGPSGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKYTSPPQNHGFDYWGQGTLVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Пример 2: Группа из 4 дубликатов\n",
      "Различающиеся поля: target_pdb\n",
      "================================================================================\n",
      "\n",
      "--- Запись 1 (индекс 68) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLVESGGGLVQPGGSLRLSCAASGFTNDFYSIAWFRQAPGKEREGVSWLSVSDNTPTYVDSVKDRFTISRHNANNTVYLQMNMLKPEDTAIYYCAAGRFAGRDTWPSSYDYWGQGTQVTVSSKHHHHHH\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: HHHHHHTNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGKK\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"8c3v\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFTNDFYS\",\n",
      "    \"cdr2_aa\": \"LSVSDNTP\",\n",
      "    \"cdr3_aa\": \"AAGRFAGRDTWPSSYDY\",\n",
      "    \"sequence_alignment_aa\": \"QVQLVESGGGLVQPGGSLRLSCAASGFTNDFYSIAWFRQAPGKEREGVSWLSVSDNTPTYVDSVKDRFTISRHNANNTVYLQMNMLKPEDTAIYYCAAGRFAGRDTWPSSYDYWGQGTQVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "--- Запись 2 (индекс 69) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLVESGGGLVQPGGSLRLSCAASGFTNDFYSIAWFRQAPGKEREGVSWLSVSDNTPTYVDSVKDRFTISRHNANNTVYLQMNMLKPEDTAIYYCAAGRFAGRDTWPSSYDYWGQGTQVTVSSKHHHHHH\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: HHHHHHTNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGKK\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"8c3v\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GFTNDFYS\",\n",
      "    \"cdr2_aa\": \"LSVSDNTP\",\n",
      "    \"cdr3_aa\": \"AAGRFAGRDTWPSSYDY\",\n",
      "    \"sequence_alignment_aa\": \"QVQLVESGGGLVQPGGSLRLSCAASGFTNDFYSIAWFRQAPGKEREGVSWLSVSDNTPTYVDSVKDRFTISRHNANNTVYLQMNMLKPEDTAIYYCAAGRFAGRDTWPSSYDYWGQGTQVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Пример 3: Группа из 4 дубликатов\n",
      "Различающиеся поля: target_pdb\n",
      "================================================================================\n",
      "\n",
      "--- Запись 1 (индекс 154) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLAESGGGLVQAGGSLRLSCAASGRTFSDYAMGWFRQAPGKERDFVAGITSSGGGTYYADSVKGRFTITRDNYKNTLYLQMDSLKPEDTAVYYCKGTADGSSSLGYLEVWGQGTLVTVSSEPKTPKPQ\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: ADVCMDPEPIVRIVGRNGLCVDVRDGRFHNGNAIQLWPCKSNTDANQLWTLKRDNTIRSNGKCLTTYGYSPGVYVMIYDCNTAATDATRWQIWDNGTIINPRSSLVLAATSGNSGTTLTVQTNIYAVSQGWLPTNNTQPFVTTIVGLYGLCLQANSGQVWIEDCSSEKAEQQWALYADGSIRPQQNRDNCLTSDSNIRETVVKILSCGPASSGQRWMFKNDGTILNLYSGLVLDVRASDPSLKQIILYPLHGDPNQIWLPLF\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"7kdm\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GRTFSDYA\",\n",
      "    \"cdr2_aa\": \"ITSSGGGT\",\n",
      "    \"cdr3_aa\": \"KGTADGSSSLGYLEV\",\n",
      "    \"sequence_alignment_aa\": \"QVQLAESGGGLVQAGGSLRLSCAASGRTFSDYAMGWFRQAPGKERDFVAGITSSGGGTYYADSVKGRFTITRDNYKNTLYLQMDSLKPEDTAVYYCKGTADGSSSLGYLEVWGQGTLVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "--- Запись 2 (индекс 155) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLAESGGGLVQAGGSLRLSCAASGRTFSDYAMGWFRQAPGKERDFVAGITSSGGGTYYADSVKGRFTITRDNYKNTLYLQMDSLKPEDTAVYYCKGTADGSSSLGYLEVWGQGTLVTVSSEPKTPKPQ\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: ADVCMDPEPIVRIVGRNGLCVDVRDGRFHNGNAIQLWPCKSNTDANQLWTLKRDNTIRSNGKCLTTYGYSPGVYVMIYDCNTAATDATRWQIWDNGTIINPRSSLVLAATSGNSGTTLTVQTNIYAVSQGWLPTNNTQPFVTTIVGLYGLCLQANSGQVWIEDCSSEKAEQQWALYADGSIRPQQNRDNCLTSDSNIRETVVKILSCGPASSGQRWMFKNDGTILNLYSGLVLDVRASDPSLKQIILYPLHGDPNQIWLPLF\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"7kdm\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GRTFSDYA\",\n",
      "    \"cdr2_aa\": \"ITSSGGGT\",\n",
      "    \"cdr3_aa\": \"KGTADGSSSLGYLEV\",\n",
      "    \"sequence_alignment_aa\": \"QVQLAESGGGLVQAGGSLRLSCAASGRTFSDYAMGWFRQAPGKERDFVAGITSSGGGTYYADSVKGRFTITRDNYKNTLYLQMDSLKPEDTAVYYCKGTADGSSSLGYLEVWGQGTLVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Пример 4: Группа из 9 дубликатов\n",
      "Различающиеся поля: target_pdb\n",
      "================================================================================\n",
      "\n",
      "--- Запись 1 (индекс 158) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLQESGGGLVQAGSSLRLACAATGSIRSINNMGWYRQAPGKQRGMVAIITRVGNTDYADSVKGRFTISRDNAKNTVYLQMNSLKPEDTATYYCHAEITEQSRPFYLTDDYWGQGTQVTVSSAAAHHHHHHGAAEQKLISEEDLNGAA\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: SLTTTEVVMENVTAFWEEGGTPVLKDINFKIERGQLLAVAGSTGAGKTSLLMMIMGELEPSEGKIKHSGRISFCSQFSWIMPGTIKENIIFGVSYDEYRYRSVIKACQLEEDISKFAEKDNIVLGEGGITLSGGQRARISLARAVYKDADLYLLDSPFGYLDVLTEKEIFESCVCKLMANKTRILVTSKMEHLKKADKILILHEGSSYFYGTFSELQNLQPDFSSKLMG\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"6gkd\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GSIRSINN\",\n",
      "    \"cdr2_aa\": \"ITRVGNT\",\n",
      "    \"cdr3_aa\": \"HAEITEQSRPFYLTDDY\",\n",
      "    \"sequence_alignment_aa\": \"QVQLQESGGGLVQAGSSLRLACAATGSIRSINNMGWYRQAPGKQRGMVAIITRVGNTDYADSVKGRFTISRDNAKNTVYLQMNSLKPEDTATYYCHAEITEQSRPFYLTDDYWGQGTQVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "--- Запись 2 (индекс 159) ---\n",
      "dataset: structures-nanobodies\n",
      "heavy_sequence: QVQLQESGGGLVQAGSSLRLACAATGSIRSINNMGWYRQAPGKQRGMVAIITRVGNTDYADSVKGRFTISRDNAKNTVYLQMNSLKPEDTATYYCHAEITEQSRPFYLTDDYWGQGTQVTVSSAAAHHHHHHGAAEQKLISEEDLNGAA\n",
      "light_sequence: \n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: SLTTTEVVMENVTAFWEEGGTPVLKDINFKIERGQLLAVAGSTGAGKTSLLMMIMGELEPSEGKIKHSGRISFCSQFSWIMPGTIKENIIFGVSYDEYRYRSVIKACQLEEDISKFAEKDNIVLGEGGITLSGGQRARISLARAVYKDADLYLLDSPFGYLDVLTEKEIFESCVCKLMANKTRILVTSKMEHLKKADKILILHEGSSYFYGTFSELQNLQPDFSSKLMG\n",
      "confidence: very_high\n",
      "nanobody: True\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"6gkd\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GSIRSINN\",\n",
      "    \"cdr2_aa\": \"ITRVGNT\",\n",
      "    \"cdr3_aa\": \"HAEITEQSRPFYLTDDY\",\n",
      "    \"sequence_alignment_aa\": \"QVQLQESGGGLVQAGSSLRLACAATGSIRSINNMGWYRQAPGKQRGMVAIITRVGNTDYADSVKGRFTISRDNAKNTVYLQMNSLKPEDTATYYCHAEITEQSRPFYLTDDYWGQGTQVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": null,\n",
      "    \"cdr2_aa\": null,\n",
      "    \"cdr3_aa\": null,\n",
      "    \"sequence_alignment_aa\": null\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Пример 5: Группа из 2 дубликатов\n",
      "Различающиеся поля: target_pdb\n",
      "================================================================================\n",
      "\n",
      "--- Запись 1 (индекс 189) ---\n",
      "dataset: structures-antibodies\n",
      "heavy_sequence: QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLEWIGEIIPSYGRANYNEKIQKKATLTADKSSSTAFMQLSSLTSEDSAVYYCARERGDGYFAVWGAGTTVTVSSAKTTPPSVYPLAPGSAAQTNSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSSWPSETVTCNVAHPASSTKVDKKIVPRD\n",
      "light_sequence: DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRLLIKYASESISGIPSRFSGSGSGTDFTLSINSVESEDIANYYCQQSNRWPFTFGSGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRN\n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: MPPMLSGLLARLVKLLLGRHGSALHWRAAGAATVLLVIVLLAGSYLAVLAERGAPGAQLITYPRALWWSVETATTVGYGDLYPVTLWGRCVAVVVMVAGITSFGLVTAALATWFVGREQERRGH\n",
      "confidence: very_high\n",
      "nanobody: False\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"2w0f\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GYTFTSDW\",\n",
      "    \"cdr2_aa\": \"IIPSYGRA\",\n",
      "    \"cdr3_aa\": \"ARERGDGYFAV\",\n",
      "    \"sequence_alignment_aa\": \"QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLEWIGEIIPSYGRANYNEKIQKKATLTADKSSSTAFMQLSSLTSEDSAVYYCARERGDGYFAVWGAGTTVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"QSIGTD\",\n",
      "    \"cdr2_aa\": \"YAS\",\n",
      "    \"cdr3_aa\": \"QQSNRWPFT\",\n",
      "    \"sequence_alignment_aa\": \"DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRLLIKYASESISGIPSRFSGSGSGTDFTLSINSVESEDIANYYCQQSNRWPFTFGSGTKLEIK\"\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "--- Запись 2 (индекс 190) ---\n",
      "dataset: structures-antibodies\n",
      "heavy_sequence: QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLEWIGEIIPSYGRANYNEKIQKKATLTADKSSSTAFMQLSSLTSEDSAVYYCARERGDGYFAVWGAGTTVTVSSAKTTPPSVYPLAPGSAAQTNSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSSWPSETVTCNVAHPASSTKVDKKIVPRD\n",
      "light_sequence: DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRLLIKYASESISGIPSRFSGSGSGTDFTLSINSVESEDIANYYCQQSNRWPFTFGSGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRN\n",
      "scfv: False\n",
      "affinity_type: bool\n",
      "affinity: 1.0\n",
      "antigen_sequence: MPPMLSGLLARLVKLLLGRHGSALHWRAAGAATVLLVIVLLAGSYLAVLAERGAPGAQLITYPRALWWSVETATTVGYGDLYPVTLWGRCVAVVVMVAGITSFGLVTAALATWFVGREQERRGH\n",
      "confidence: very_high\n",
      "nanobody: False\n",
      "metadata:\n",
      "{\n",
      "  \"target_name\": \"\",\n",
      "  \"target_pdb\": \"2jk5\",\n",
      "  \"target_uniprot\": \"\",\n",
      "  \"source_url\": \"https://www.naturalantibody.com/na-structural/\",\n",
      "  \"heavy_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"GYTFTSDW\",\n",
      "    \"cdr2_aa\": \"IIPSYGRA\",\n",
      "    \"cdr3_aa\": \"ARERGDGYFAV\",\n",
      "    \"sequence_alignment_aa\": \"QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLEWIGEIIPSYGRANYNEKIQKKATLTADKSSSTAFMQLSSLTSEDSAVYYCARERGDGYFAVWGAGTTVTVSS\"\n",
      "  },\n",
      "  \"light_riot_numbering\": {\n",
      "    \"cdr1_aa\": \"QSIGTD\",\n",
      "    \"cdr2_aa\": \"YAS\",\n",
      "    \"cdr3_aa\": \"QQSNRWPFT\",\n",
      "    \"sequence_alignment_aa\": \"DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRLLIKYASESISGIPSRFSGSGSGTDFTLSINSVESEDIANYYCQQSNRWPFTFGSGTKLEIK\"\n",
      "  }\n",
      "}\n",
      "processed_measurement: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== АНАЛИЗ РАЗЛИЧИЙ В METADATA МЕЖДУ ДУБЛИКАТАМИ В AGAB ===\\n\")\n",
    "\n",
    "# Находим дубликаты в agab_df по всем колонкам кроме metadata\n",
    "agab_duplicates_mask = agab_df.drop(columns=['metadata']).duplicated(keep=False)\n",
    "agab_duplicates = agab_df[agab_duplicates_mask].copy()\n",
    "\n",
    "# Создаем ключ для группировки\n",
    "agab_duplicates['duplicate_key'] = agab_duplicates.drop(columns=['metadata']).apply(tuple, axis=1)\n",
    "\n",
    "# Получаем уникальные группы дубликатов\n",
    "unique_duplicate_groups = agab_duplicates['duplicate_key'].unique()\n",
    "\n",
    "print(f\"Всего групп дубликатов: {len(unique_duplicate_groups)}\\n\")\n",
    "\n",
    "# Функция для рекурсивного сравнения словарей и поиска различий\n",
    "def find_different_keys(dict1, dict2, path=\"\"):\n",
    "    \"\"\"Находит все ключи, которые различаются между двумя словарями\"\"\"\n",
    "    different_keys = set()\n",
    "    \n",
    "    if not isinstance(dict1, dict) or not isinstance(dict2, dict):\n",
    "        if dict1 != dict2:\n",
    "            return {path} if path else set()\n",
    "        return set()\n",
    "    \n",
    "    all_keys = set(dict1.keys()) | set(dict2.keys())\n",
    "    \n",
    "    for key in all_keys:\n",
    "        current_path = f\"{path}.{key}\" if path else key\n",
    "        val1 = dict1.get(key)\n",
    "        val2 = dict2.get(key)\n",
    "        \n",
    "        if key not in dict1:\n",
    "            different_keys.add(current_path)\n",
    "        elif key not in dict2:\n",
    "            different_keys.add(current_path)\n",
    "        elif isinstance(val1, dict) and isinstance(val2, dict):\n",
    "            different_keys.update(find_different_keys(val1, val2, current_path))\n",
    "        elif val1 != val2:\n",
    "            different_keys.add(current_path)\n",
    "    \n",
    "    return different_keys\n",
    "\n",
    "# Собираем статистику по различиям\n",
    "field_differences = Counter()\n",
    "groups_with_differences = 0\n",
    "groups_with_same_metadata = 0\n",
    "total_groups_analyzed = 0\n",
    "\n",
    "# Анализируем каждую группу дубликатов\n",
    "for group_key in unique_duplicate_groups:\n",
    "    group_data = agab_duplicates[agab_duplicates['duplicate_key'] == group_key]\n",
    "    \n",
    "    if len(group_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    total_groups_analyzed += 1\n",
    "    \n",
    "    # Сравниваем metadata между всеми парами в группе\n",
    "    metadata_list = group_data['metadata'].tolist()\n",
    "    \n",
    "    # Проверяем, все ли metadata одинаковые\n",
    "    all_same = True\n",
    "    group_differences = set()\n",
    "    \n",
    "    for i in range(len(metadata_list)):\n",
    "        for j in range(i + 1, len(metadata_list)):\n",
    "            meta1 = metadata_list[i] if isinstance(metadata_list[i], dict) else {}\n",
    "            meta2 = metadata_list[j] if isinstance(metadata_list[j], dict) else {}\n",
    "            \n",
    "            diff_keys = find_different_keys(meta1, meta2)\n",
    "            if diff_keys:\n",
    "                all_same = False\n",
    "                group_differences.update(diff_keys)\n",
    "    \n",
    "    if all_same:\n",
    "        groups_with_same_metadata += 1\n",
    "    else:\n",
    "        groups_with_differences += 1\n",
    "        for key in group_differences:\n",
    "            field_differences[key] += 1\n",
    "\n",
    "print(f\"Проанализировано групп: {total_groups_analyzed}\")\n",
    "print(f\"Групп с одинаковым metadata: {groups_with_same_metadata} ({groups_with_same_metadata/total_groups_analyzed*100:.2f}%)\")\n",
    "print(f\"Групп с различиями в metadata: {groups_with_differences} ({groups_with_differences/total_groups_analyzed*100:.2f}%)\\n\")\n",
    "\n",
    "if field_differences:\n",
    "    print(\"=== ПОЛЯ METADATA, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\\n\")\n",
    "    for field, count in field_differences:\n",
    "        pct = count / groups_with_differences * 100\n",
    "        print(f\"{field}: {count} групп ({pct:.2f}% от групп с различиями)\")\n",
    "    \n",
    "    print(f\"\\nВсего уникальных полей с различиями: {len(field_differences)}\")\n",
    "else:\n",
    "    print(\"Различий в metadata между дубликатами не найдено.\")\n",
    "\n",
    "# Показываем примеры групп с различиями\n",
    "print(\"\\n=== ПРИМЕРЫ ГРУПП С РАЗЛИЧИЯМИ В METADATA ===\\n\")\n",
    "\n",
    "examples_shown = 0\n",
    "for group_key in unique_duplicate_groups:\n",
    "    if examples_shown >= 5:\n",
    "        break\n",
    "    \n",
    "    group_data = agab_duplicates[agab_duplicates['duplicate_key'] == group_key].copy()\n",
    "    \n",
    "    if len(group_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    metadata_list = group_data['metadata'].tolist()\n",
    "    \n",
    "    # Проверяем, есть ли различия\n",
    "    has_differences = False\n",
    "    all_differences = set()\n",
    "    \n",
    "    for i in range(len(metadata_list)):\n",
    "        for j in range(i + 1, len(metadata_list)):\n",
    "            meta1 = metadata_list[i] if isinstance(metadata_list[i], dict) else {}\n",
    "            meta2 = metadata_list[j] if isinstance(metadata_list[j], dict) else {}\n",
    "            \n",
    "            diff_keys = find_different_keys(meta1, meta2)\n",
    "            if diff_keys:\n",
    "                has_differences = True\n",
    "                all_differences.update(diff_keys)\n",
    "    \n",
    "    if has_differences:\n",
    "        examples_shown += 1\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Пример {examples_shown}: Группа из {len(group_data)} дубликатов\")\n",
    "        print(f\"Различающиеся поля: {', '.join(sorted(all_differences))}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Показываем первые 2 записи из группы\n",
    "        for idx, (row_idx, row) in enumerate(group_data.head(2).iterrows()):\n",
    "            print(f\"--- Запись {idx+1} (индекс {row_idx}) ---\")\n",
    "            \n",
    "            # Показываем все колонки кроме duplicate_key\n",
    "            display_cols = [col for col in group_data.columns if col not in ['duplicate_key']]\n",
    "            \n",
    "            for col in display_cols:\n",
    "                if col == 'metadata':\n",
    "                    # Красиво выводим metadata\n",
    "                    metadata_str = json.dumps(row[col], indent=2, ensure_ascii=False) if isinstance(row[col], dict) else str(row[col])\n",
    "                    print(f\"{col}:\\n{metadata_str}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {row[col]}\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Удаляем временную колонку\n",
    "agab_duplicates.drop(columns=['duplicate_key'], inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (antibody_env)",
   "language": "python",
   "name": "antibody_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
