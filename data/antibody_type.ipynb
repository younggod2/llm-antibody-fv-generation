{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b5e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cd9595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 20 parquet файлов\n",
      "Общий размер данных: (1227083, 11)\n",
      "Колонки: ['dataset', 'heavy_sequence', 'light_sequence', 'scfv', 'affinity_type', 'affinity', 'antigen_sequence', 'confidence', 'nanobody', 'metadata', 'processed_measurement']\n"
     ]
    }
   ],
   "source": [
    "def load_asd_data_with_pandas(data_path: str = \"/content/drive/MyDrive/Antibody_Chekalin_Denis/asd\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает все parquet файлы из папки asd в один pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        data_path: путь к папке с данными\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: объединенный DataFrame со всеми данными\n",
    "    \"\"\"\n",
    "    # Получаем все parquet файлы из папки\n",
    "    parquet_files = glob.glob(os.path.join(data_path, \"part-*.parquet\"))\n",
    "\n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"Не найдено parquet файлов в папке {data_path}\")\n",
    "\n",
    "    print(f\"Найдено {len(parquet_files)} parquet файлов\")\n",
    "\n",
    "    # Загружаем все файлы в список DataFrame'ов\n",
    "    dataframes = []\n",
    "    for file_path in parquet_files:\n",
    "        # print(f\"Загружаем файл: {os.path.basename(file_path)}\")\n",
    "        df = pd.read_parquet(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Объединяем все DataFrame'ы в один\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    print(f\"Общий размер данных: {combined_df.shape}\")\n",
    "    print(f\"Колонки: {list(combined_df.columns)}\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Загружаем данные\n",
    "agab_df = load_asd_data_with_pandas('./asd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f65a2",
   "metadata": {},
   "source": [
    "### Распределение типов антител"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfdaaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение записей по типам антител:\n",
      "antibody_type\n",
      "Paired (heavy + light)    716176\n",
      "Heavy-only                188742\n",
      "scFv                      132157\n",
      "Nanobody                  110904\n",
      "Light-only                 79104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Процентное распределение:\n",
      "antibody_type\n",
      "Paired (heavy + light)    58.364104\n",
      "Heavy-only                15.381356\n",
      "scFv                      10.770013\n",
      "Nanobody                   9.038019\n",
      "Light-only                 6.446508\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "Детальный анализ записей с scFv == False и nanobody == False:\n",
      "============================================================\n",
      "\n",
      "Всего таких записей: 980878\n",
      "\n",
      "Распределение по типам среди отфильтрованных записей:\n",
      "Paired (heavy + light)    713227\n",
      "Heavy-only                188626\n",
      "Light-only                 79025\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Процентное распределение:\n",
      "Paired (heavy + light)    72.713120\n",
      "Heavy-only                19.230322\n",
      "Light-only                 8.056557\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Создаем категории записей\n",
    "def categorize_antibody(row):\n",
    "    \"\"\"Категоризирует запись по типу антитела\"\"\"\n",
    "    has_heavy = pd.notna(row['heavy_sequence']) and row['heavy_sequence'] != ''\n",
    "    has_light = pd.notna(row['light_sequence']) and row['light_sequence'] != ''\n",
    "    \n",
    "    if row['scfv'] == True:\n",
    "        return 'scFv'\n",
    "    elif row['nanobody'] == True:\n",
    "        return 'Nanobody'\n",
    "    elif has_heavy and has_light:\n",
    "        return 'Paired (heavy + light)'\n",
    "    elif has_heavy and not has_light:\n",
    "        return 'Heavy-only'\n",
    "    elif not has_heavy and has_light:\n",
    "        return 'Light-only'\n",
    "    else:\n",
    "        return 'No sequences'\n",
    "\n",
    "# Применяем категоризацию\n",
    "agab_df['antibody_type'] = agab_df.apply(categorize_antibody, axis=1)\n",
    "\n",
    "# Распределение по типам\n",
    "print(\"Распределение записей по типам антител:\")\n",
    "print(agab_df['antibody_type'].value_counts())\n",
    "print(\"\\nПроцентное распределение:\")\n",
    "print(agab_df['antibody_type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Фокус на записях с scFv == False и nanobody == False\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Детальный анализ записей с scFv == False и nanobody == False:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "filtered_df = agab_df[\n",
    "    (agab_df['scfv'] == False) \n",
    "    & (agab_df['nanobody'] == False)\n",
    "]\n",
    "\n",
    "print(f\"\\nВсего таких записей: {len(filtered_df)}\")\n",
    "\n",
    "# Распределение по типам среди отфильтрованных\n",
    "print(\"\\nРаспределение по типам среди отфильтрованных записей:\")\n",
    "filtered_types = filtered_df.apply(categorize_antibody, axis=1)\n",
    "print(filtered_types.value_counts())\n",
    "print(\"\\nПроцентное распределение:\")\n",
    "print(filtered_types.value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5feb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей с scFv == False и nanobody == False: 980878\n",
      "\n",
      "Распределение по dataset для записей с пустыми light_sequence:\n",
      "dataset\n",
      "patents       76588\n",
      "covid-19      54625\n",
      "hiv           48008\n",
      "met            4000\n",
      "biomap         2725\n",
      "genbank        2603\n",
      "literature       42\n",
      "aae              35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Распределение по dataset для записей с пустыми heavy_sequence:\n",
      "dataset\n",
      "patents    78737\n",
      "genbank      288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Всего записей с scFv == False и nanobody == False: {len(filtered_df)}\")\n",
    "\n",
    "# Смотрим на распределение по dataset\n",
    "print(\"\\nРаспределение по dataset для записей с пустыми light_sequence:\")\n",
    "print(empty_light['dataset'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nРаспределение по dataset для записей с пустыми heavy_sequence:\")\n",
    "print(empty_heavy['dataset'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb6459",
   "metadata": {},
   "source": [
    "### Смотрим на примере dataset = patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa0dfd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для dataset = patents:\n",
      "  Пустые оба (light_sequence и heavy_sequence): 0\n",
      "  Пустой только light_sequence: 76588\n",
      "  Пустой только heavy_sequence: 78737\n",
      "  Оба заполнены: 21621\n"
     ]
    }
   ],
   "source": [
    "# Считаем количество записей с пустыми light_sequence и heavy_sequence для dataset = patents\n",
    "\n",
    "# Фильтрация по dataset = patents и scFv == False и nanobody == False\n",
    "patents_df = agab_df[\n",
    "    (agab_df['dataset'] == 'patents')\n",
    "    & (agab_df['scfv'] == False)\n",
    "    & (agab_df['nanobody'] == False)\n",
    "]\n",
    "\n",
    "# Условия для пустых light_sequence и heavy_sequence\n",
    "empty_light_patents = patents_df['light_sequence'].isnull() | (patents_df['light_sequence'] == '')\n",
    "empty_heavy_patents = patents_df['heavy_sequence'].isnull() | (patents_df['heavy_sequence'] == '')\n",
    "\n",
    "# Подсчёт количества каждого случая\n",
    "both_empty = patents_df[empty_light_patents & empty_heavy_patents].shape[0]\n",
    "only_light_empty = patents_df[empty_light_patents & ~empty_heavy_patents].shape[0]\n",
    "only_heavy_empty = patents_df[~empty_light_patents & empty_heavy_patents].shape[0]\n",
    "none_empty = patents_df[~empty_light_patents & ~empty_heavy_patents].shape[0]\n",
    "\n",
    "print(\"Для dataset = patents:\")\n",
    "print(f\"  Пустые оба (light_sequence и heavy_sequence): {both_empty}\")\n",
    "print(f\"  Пустой только light_sequence: {only_light_empty}\")\n",
    "print(f\"  Пустой только heavy_sequence: {only_heavy_empty}\")\n",
    "print(f\"  Оба заполнены: {none_empty}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
