{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c265d56f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "from anarci import anarci\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "c8191907",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найдено 20 parquet файлов\n",
            "Общий размер данных: (1199759, 11)\n",
            "Колонки: ['dataset', 'heavy_sequence', 'light_sequence', 'scfv', 'affinity_type', 'affinity', 'antigen_sequence', 'confidence', 'nanobody', 'metadata', 'processed_measurement']\n"
          ]
        }
      ],
      "source": [
        "def load_asd_data_with_pandas(data_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Загружает все parquet файлы из папки asd в один pandas DataFrame\n",
        "\n",
        "    Args:\n",
        "        data_path: путь к папке с данными\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: объединенный DataFrame со всеми данными\n",
        "    \"\"\"\n",
        "    # Получаем все parquet файлы из папки\n",
        "    parquet_files = glob.glob(os.path.join(data_path, \"part-*.parquet\"))\n",
        "\n",
        "    if not parquet_files:\n",
        "        raise ValueError(f\"Не найдено parquet файлов в папке {data_path}\")\n",
        "\n",
        "    print(f\"Найдено {len(parquet_files)} parquet файлов\")\n",
        "\n",
        "    # Загружаем все файлы в список DataFrame'ов\n",
        "    dataframes = []\n",
        "    for file_path in parquet_files:\n",
        "        df = pd.read_parquet(file_path)\n",
        "        dataframes.append(df)\n",
        "\n",
        "    # Объединяем все DataFrame'ы в один\n",
        "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    print(f\"Общий размер данных: {combined_df.shape}\")\n",
        "    print(f\"Колонки: {list(combined_df.columns)}\")\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# Загружаем данные\n",
        "agab_df = load_asd_data_with_pandas('./asd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "2c705170",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Переводим affinity и processed_measurement во float где возможно\n",
        "# Convert strings to floats, handling \">8.8\" or \"<0.01\" patterns\n",
        "def convert_to_float(value):\n",
        "    \"\"\"Convert string values like '>8.8' or '<0.01' to floats (8.8 and 0.01)\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return value\n",
        "    if isinstance(value, (int, float)):\n",
        "        return float(value)\n",
        "    if isinstance(value, str):\n",
        "        # Remove leading > or < and convert to float\n",
        "        cleaned = value.strip()\n",
        "        if cleaned.startswith('>') or cleaned.startswith('<'):\n",
        "            cleaned = cleaned[1:].strip()\n",
        "        try:\n",
        "            return float(cleaned)\n",
        "        except (ValueError, TypeError):\n",
        "            return value\n",
        "    return value\n",
        "\n",
        "# Apply conversion to processed_measurement\n",
        "agab_df = agab_df.copy()\n",
        "agab_df.loc[:, 'affinity'] = pd.to_numeric(agab_df['affinity'], errors='coerce').fillna(agab_df['affinity'])\n",
        "agab_df.loc[:, 'processed_measurement'] = pd.to_numeric(agab_df['processed_measurement'], errors='coerce').fillna(agab_df['processed_measurement'])\n",
        "\n",
        "agab_df['affinity'] = agab_df['affinity'].apply(convert_to_float)\n",
        "agab_df['processed_measurement'] = agab_df['processed_measurement'].apply(convert_to_float)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8a2ab3",
      "metadata": {},
      "source": [
        "#### Base filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "4353ef9b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(844872, 11)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_not_nanobody = agab_df['nanobody'] == False\n",
        "# is_high_confidence = agab_df['confidence'].isin(['high', 'very_high'])\n",
        "is_scfv = agab_df['scfv'] == True\n",
        "has_both_chains = (\n",
        "    agab_df['light_sequence'].notna() \n",
        "    & agab_df['heavy_sequence'].notna()\n",
        "    & (agab_df['light_sequence'] != '')\n",
        "    & (agab_df['heavy_sequence'] != '')\n",
        ")\n",
        "\n",
        "agab_df = agab_df[is_not_nanobody \n",
        "# & is_high_confidence \n",
        "& (is_scfv | has_both_chains)]\n",
        "agab_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "284e1d2b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>total_count</th>\n",
              "      <th>unique_antigens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>affinity_type</th>\n",
              "      <th>dataset</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">bool</th>\n",
              "      <th>patents</th>\n",
              "      <td>21621</td>\n",
              "      <td>3478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>structures-antibodies</th>\n",
              "      <td>2711</td>\n",
              "      <td>1083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genbank</th>\n",
              "      <td>98</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skempiv2</th>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ddg</th>\n",
              "      <th>skempiv2</th>\n",
              "      <td>400</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>elisa_mut_to_wt_ratio</th>\n",
              "      <th>abdesign</th>\n",
              "      <td>658</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">bool</th>\n",
              "      <th>abdesign</th>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ab-bind</th>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ic_50</th>\n",
              "      <th>dlgo</th>\n",
              "      <td>360</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ddg</th>\n",
              "      <th>ab-bind</th>\n",
              "      <td>270</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-log KD</th>\n",
              "      <th>abbd</th>\n",
              "      <td>152401</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kd</th>\n",
              "      <th>flab_hie2022</th>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alphaseq</th>\n",
              "      <th>alphaseq</th>\n",
              "      <td>131645</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">kd</th>\n",
              "      <th>flab_shanehsazzadeh2023</th>\n",
              "      <td>446</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flab_rosace2023</th>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long_enrichment</th>\n",
              "      <th>abbd</th>\n",
              "      <td>3452</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fuzzy</th>\n",
              "      <th>buzz</th>\n",
              "      <td>524346</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">kd</th>\n",
              "      <th>flab_koenig2017</th>\n",
              "      <td>4275</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flab_warszawski2019</th>\n",
              "      <td>2048</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               total_count  unique_antigens\n",
              "affinity_type         dataset                                              \n",
              "bool                  patents                        21621             3478\n",
              "                      structures-antibodies           2711             1083\n",
              "                      genbank                           98               23\n",
              "                      skempiv2                          34               21\n",
              "ddg                   skempiv2                         400               19\n",
              "elisa_mut_to_wt_ratio abdesign                         658               13\n",
              "bool                  abdesign                          14               13\n",
              "                      ab-bind                           13               10\n",
              "ic_50                 dlgo                             360               10\n",
              "ddg                   ab-bind                          270                9\n",
              "-log KD               abbd                          152401                5\n",
              "kd                    flab_hie2022                      55                3\n",
              "alphaseq              alphaseq                      131645                2\n",
              "kd                    flab_shanehsazzadeh2023          446                2\n",
              "                      flab_rosace2023                   25                2\n",
              "long_enrichment       abbd                            3452                2\n",
              "fuzzy                 buzz                          524346                1\n",
              "kd                    flab_koenig2017                 4275                1\n",
              "                      flab_warszawski2019             2048                1"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agab_df.groupby(['affinity_type', 'dataset'])['antigen_sequence'].agg([\n",
        "    ('total_count', 'count'),\n",
        "    ('unique_antigens', 'nunique')\n",
        "]).sort_values('unique_antigens', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "e8fd79b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "После базовых фильтров: (844872, 11)\n",
            "Распределение по affinity_type до фильтрации по порогам:\n",
            "affinity_type\n",
            "fuzzy                    524346\n",
            "-log KD                  152401\n",
            "alphaseq                 131645\n",
            "bool                      24491\n",
            "kd                         6849\n",
            "long_enrichment            3452\n",
            "ddg                         670\n",
            "elisa_mut_to_wt_ratio       658\n",
            "ic_50                       360\n",
            "Name: count, dtype: int64\n",
            "\n",
            "После фильтрации по порогам аффинитета: (401505, 11)\n",
            "Распределение по affinity_type после фильтрации:\n",
            "affinity_type\n",
            "fuzzy                    172149\n",
            "-log KD                  141805\n",
            "alphaseq                  55670\n",
            "bool                      24491\n",
            "kd                         6744\n",
            "ic_50                       309\n",
            "ddg                         169\n",
            "elisa_mut_to_wt_ratio       168\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# (порог, оператор): '<', '>', '=='\n",
        "AFFINITY_THRESHOLDS = {\n",
        "    'fuzzy': ('h', '=='),\n",
        "    'bool': (1, '=='),\n",
        "    'alphaseq': (2, '<'),\n",
        "    '-log KD': (7, '>'),\n",
        "    'kd': (100, '<'),\n",
        "    # 'delta_g': (-9.5, '<'), ее нет\n",
        "    'ddg': (0, '<'),  \n",
        "    'log_enrichment': (0, '>'),\n",
        "    'elisa_mut_to_wt_ratio': (1, '>'),\n",
        "    'ic_50': (1, '<'), # мкг/мл \n",
        "}\n",
        "\n",
        "def apply_affinity_filter(df: pd.DataFrame, thresholds: dict) -> pd.DataFrame:\n",
        "    masks = []\n",
        "    for affinity_type, (threshold, op) in thresholds.items():\n",
        "        type_mask = df['affinity_type'] == affinity_type\n",
        "        if op == '==':\n",
        "            mask = type_mask & (df['processed_measurement'] == threshold)\n",
        "        else:\n",
        "            numeric_affinity = pd.to_numeric(df['processed_measurement'], errors='coerce')\n",
        "            if op == '<':\n",
        "                mask = type_mask & (numeric_affinity < threshold)\n",
        "            else:\n",
        "                mask = type_mask & (numeric_affinity > threshold)\n",
        "        masks.append(mask)\n",
        "\n",
        "    if masks:\n",
        "        combined_mask = masks[0]\n",
        "        for mask in masks[1:]:\n",
        "            combined_mask = combined_mask | mask\n",
        "        return df[combined_mask]\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "print(f\"После базовых фильтров: {agab_df.shape}\")\n",
        "print(f\"Распределение по affinity_type до фильтрации по порогам:\")\n",
        "print(agab_df['affinity_type'].value_counts())\n",
        "\n",
        "# Применяем фильтрацию по порогам аффиности\n",
        "agab_df = apply_affinity_filter(agab_df, AFFINITY_THRESHOLDS)\n",
        "\n",
        "print(f\"\\nПосле фильтрации по порогам аффинитета: {agab_df.shape}\")\n",
        "print(f\"Распределение по affinity_type после фильтрации:\")\n",
        "print(agab_df['affinity_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "c3481668",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>total_count</th>\n",
              "      <th>unique_antigens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>affinity_type</th>\n",
              "      <th>dataset</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">bool</th>\n",
              "      <th>patents</th>\n",
              "      <td>21621</td>\n",
              "      <td>3478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>structures-antibodies</th>\n",
              "      <td>2711</td>\n",
              "      <td>1083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genbank</th>\n",
              "      <td>98</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skempiv2</th>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ddg</th>\n",
              "      <th>skempiv2</th>\n",
              "      <td>112</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bool</th>\n",
              "      <th>abdesign</th>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>elisa_mut_to_wt_ratio</th>\n",
              "      <th>abdesign</th>\n",
              "      <td>168</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bool</th>\n",
              "      <th>ab-bind</th>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ic_50</th>\n",
              "      <th>dlgo</th>\n",
              "      <td>309</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ddg</th>\n",
              "      <th>ab-bind</th>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-log KD</th>\n",
              "      <th>abbd</th>\n",
              "      <td>141805</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kd</th>\n",
              "      <th>flab_hie2022</th>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alphaseq</th>\n",
              "      <th>alphaseq</th>\n",
              "      <td>55670</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">kd</th>\n",
              "      <th>flab_rosace2023</th>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flab_shanehsazzadeh2023</th>\n",
              "      <td>341</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fuzzy</th>\n",
              "      <th>buzz</th>\n",
              "      <td>172149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">kd</th>\n",
              "      <th>flab_koenig2017</th>\n",
              "      <td>4275</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flab_warszawski2019</th>\n",
              "      <td>2048</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               total_count  unique_antigens\n",
              "affinity_type         dataset                                              \n",
              "bool                  patents                        21621             3478\n",
              "                      structures-antibodies           2711             1083\n",
              "                      genbank                           98               23\n",
              "                      skempiv2                          34               21\n",
              "ddg                   skempiv2                         112               17\n",
              "bool                  abdesign                          14               13\n",
              "elisa_mut_to_wt_ratio abdesign                         168               12\n",
              "bool                  ab-bind                           13               10\n",
              "ic_50                 dlgo                             309               10\n",
              "ddg                   ab-bind                           57                9\n",
              "-log KD               abbd                          141805                5\n",
              "kd                    flab_hie2022                      55                3\n",
              "alphaseq              alphaseq                       55670                2\n",
              "kd                    flab_rosace2023                   25                2\n",
              "                      flab_shanehsazzadeh2023          341                2\n",
              "fuzzy                 buzz                          172149                1\n",
              "kd                    flab_koenig2017                 4275                1\n",
              "                      flab_warszawski2019             2048                1"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agab_df.groupby(['affinity_type', 'dataset'])['antigen_sequence'].agg([\n",
        "    ('total_count', 'count'),\n",
        "    ('unique_antigens', 'nunique')\n",
        "]).sort_values('unique_antigens', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc6a3fc",
      "metadata": {},
      "source": [
        "#### Affinity variation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "23e1e688",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== АНАЛИЗ РАЗЛИЧИЙ В ПОЛЯХ ДЛЯ ДУБЛИКАТОВ ПО ПОСЛЕДОВАТЕЛЬНОСТЯМ (agab_df) ===\n",
            "\n",
            "Всего групп дубликатов: 64063\n",
            "\n",
            "Групп с различиями: 63380 (98.93%)\n",
            "Групп без различий: 683 (1.07%)\n",
            "\n",
            "Строк (записей) с различиями: 127441 (98.55%)\n",
            "Строк (записей) без различий: 1870 (1.45%)\n",
            "\n",
            "=== ПОЛЯ, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\n",
            "\n",
            "affinity: 63361 групп (99.97%)\n",
            "dataset: 51 групп (0.08%)\n",
            "affinity_type: 3 групп (0.00%)\n",
            "processed_measurement: 3 групп (0.00%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=== АНАЛИЗ РАЗЛИЧИЙ В ПОЛЯХ ДЛЯ ДУБЛИКАТОВ ПО ПОСЛЕДОВАТЕЛЬНОСТЯМ (agab_df) ===\\n\")\n",
        "\n",
        "# Поля для проверки\n",
        "fields = [\n",
        "    \"dataset\",\n",
        "    \"scfv\",\n",
        "    \"affinity_type\",\n",
        "    \"affinity\",\n",
        "    \"confidence\",\n",
        "    \"nanobody\",\n",
        "    \"processed_measurement\",\n",
        "]\n",
        "\n",
        "# --- Поиск групп дубликатов по heavy_sequence + light_sequence + antigen_sequence---\n",
        "# Находим группы, где хотя бы 2 записи с одинаковой парой последовательностей\n",
        "group_cols = [\"heavy_sequence\", \"light_sequence\", \"antigen_sequence\"]\n",
        "grouped = agab_df.groupby(group_cols, sort=False)\n",
        "\n",
        "# Маска строк, которые входят в группы размером > 1\n",
        "dup_mask = grouped[group_cols[0]].transform(\"size\") > 1\n",
        "hl_duplicates = agab_df.loc[dup_mask].copy()\n",
        "\n",
        "# Переиспользуем groupby только на дубликатах\n",
        "dup_groups = hl_duplicates.groupby(group_cols, sort=False)\n",
        "unique_groups_count = dup_groups.ngroups\n",
        "\n",
        "print(f\"Всего групп дубликатов: {unique_groups_count}\\n\")\n",
        "\n",
        "# --- Анализ различий по полям ---\n",
        "\n",
        "# Для каждой группы считаем, сколько уникальных значений в каждом поле\n",
        "# dropna=False, чтобы различия NaN / не-NaN тоже учитывались\n",
        "nunique_per_group = dup_groups[fields].nunique(dropna=False)\n",
        "\n",
        "# Булева матрица: True, если в группе по полю есть различия\n",
        "diff_mask = nunique_per_group > 1\n",
        "\n",
        "# Есть ли вообще различия в группе\n",
        "group_has_diffs = diff_mask.any(axis=1)\n",
        "\n",
        "groups_with_diffs = int(group_has_diffs.sum())\n",
        "groups_identical = int((~group_has_diffs).sum())\n",
        "total = groups_with_diffs + groups_identical if (groups_with_diffs + groups_identical) > 0 else 1\n",
        "\n",
        "print(f\"Групп с различиями: {groups_with_diffs} ({groups_with_diffs / total * 100:.2f}%)\")\n",
        "print(f\"Групп без различий: {groups_identical} ({groups_identical / total * 100:.2f}%)\\n\")\n",
        "\n",
        "# Количество строк (записей) с различиями и без различий\n",
        "rows_with_diffs = group_has_diffs[group_has_diffs].index  # индексы групп с различиями\n",
        "rows_without_diffs = group_has_diffs[~group_has_diffs].index  # индексы групп без различий\n",
        "\n",
        "num_rows_with_diffs = dup_groups.size().loc[rows_with_diffs].sum() if len(rows_with_diffs) > 0 else 0\n",
        "num_rows_without_diffs = dup_groups.size().loc[rows_without_diffs].sum() if len(rows_without_diffs) > 0 else 0\n",
        "rows_total = num_rows_with_diffs + num_rows_without_diffs if (num_rows_with_diffs + num_rows_without_diffs) > 0 else 1\n",
        "\n",
        "print(f\"Строк (записей) с различиями: {num_rows_with_diffs} ({num_rows_with_diffs / rows_total * 100:.2f}%)\")\n",
        "print(f\"Строк (записей) без различий: {num_rows_without_diffs} ({num_rows_without_diffs / rows_total * 100:.2f}%)\\n\")\n",
        "\n",
        "# Считаем, по скольким группам отличается каждое поле\n",
        "field_diffs_counts = diff_mask.sum().sort_values(ascending=False)\n",
        "\n",
        "if groups_with_diffs > 0 and not field_diffs_counts.empty:\n",
        "    print(\"=== ПОЛЯ, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\\n\")\n",
        "    for field, count in field_diffs_counts.items():\n",
        "        if count == 0:\n",
        "            continue\n",
        "        print(f\"{field}: {count} групп ({count / groups_with_diffs * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "b8e602e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== АНАЛИЗ РАЗБРОСА АФФИНИТЕТА В ГРУППАХ ДУБЛИКАТОВ ===\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Групп с валидными числовыми аффинитетами: 64063\n",
            "Средний разброс аффинитета в группе: 2.8959\n",
            "Медианный разброс: 3.2736\n",
            "Максимальный разброс: 3.8345\n",
            "\n",
            "ВНИМАНИЕ: В 3 группах смешаны разные типы аффинитета (сравнение может быть некорректным).\n",
            "=== ТОП-5 ГРУПП С САМЫМ БОЛЬШИМ РАЗБРОСОМ АФФИНИТЕТА ===\n",
            "\n",
            "Группа 1 (разброс 3.8345):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>confidence</th>\n",
              "      <th>processed_measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>845585</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>9.834508</td>\n",
              "      <td>high</td>\n",
              "      <td>7.917254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845586</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>6.0</td>\n",
              "      <td>high</td>\n",
              "      <td>7.917254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dataset affinity_type  affinity confidence processed_measurement\n",
              "845585    abbd       -log KD  9.834508       high              7.917254\n",
              "845586    abbd       -log KD       6.0       high              7.917254"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Группа 2 (разброс 3.7936):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>confidence</th>\n",
              "      <th>processed_measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187342</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>9.793633</td>\n",
              "      <td>high</td>\n",
              "      <td>7.896816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187343</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>6.0</td>\n",
              "      <td>high</td>\n",
              "      <td>7.896816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dataset affinity_type  affinity confidence processed_measurement\n",
              "187342    abbd       -log KD  9.793633       high              7.896816\n",
              "187343    abbd       -log KD       6.0       high              7.896816"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Группа 3 (разброс 3.7556):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>confidence</th>\n",
              "      <th>processed_measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1147556</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>9.755628</td>\n",
              "      <td>high</td>\n",
              "      <td>7.877814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147557</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>6.0</td>\n",
              "      <td>high</td>\n",
              "      <td>7.877814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dataset affinity_type  affinity confidence processed_measurement\n",
              "1147556    abbd       -log KD  9.755628       high              7.877814\n",
              "1147557    abbd       -log KD       6.0       high              7.877814"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Группа 4 (разброс 3.7512):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>confidence</th>\n",
              "      <th>processed_measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>124856</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>9.75118</td>\n",
              "      <td>high</td>\n",
              "      <td>7.87559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124857</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>6.0</td>\n",
              "      <td>high</td>\n",
              "      <td>7.87559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dataset affinity_type affinity confidence processed_measurement\n",
              "124856    abbd       -log KD  9.75118       high               7.87559\n",
              "124857    abbd       -log KD      6.0       high               7.87559"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Группа 5 (разброс 3.7379):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>confidence</th>\n",
              "      <th>processed_measurement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1026354</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>9.737911</td>\n",
              "      <td>high</td>\n",
              "      <td>7.868956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026355</th>\n",
              "      <td>abbd</td>\n",
              "      <td>-log KD</td>\n",
              "      <td>6.0</td>\n",
              "      <td>high</td>\n",
              "      <td>7.868956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dataset affinity_type  affinity confidence processed_measurement\n",
              "1026354    abbd       -log KD  9.737911       high              7.868956\n",
              "1026355    abbd       -log KD       6.0       high              7.868956"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"=== АНАЛИЗ РАЗБРОСА АФФИНИТЕТА В ГРУППАХ ДУБЛИКАТОВ ===\\n\")\n",
        "\n",
        "# Работаем с копией дубликатов\n",
        "analysis_df = hl_duplicates.copy()\n",
        "\n",
        "# Преобразуем аффинитет в числа, нечисловые значения станут NaN\n",
        "analysis_df['affinity_numeric'] = pd.to_numeric(analysis_df['affinity'], errors='coerce')\n",
        "\n",
        "# Группируем\n",
        "grouped_analysis = analysis_df.groupby(group_cols, sort=False)\n",
        "\n",
        "# Считаем размах (max - min) и проверяем единственность типа аффинитета\n",
        "agg_funcs = {\n",
        "    'affinity_numeric': lambda x: x.max() - x.min(),\n",
        "    'affinity_type': 'nunique'\n",
        "}\n",
        "\n",
        "group_stats = grouped_analysis.agg(agg_funcs)\n",
        "group_stats.columns = ['affinity_range', 'affinity_type_count']\n",
        "\n",
        "# Фильтруем группы, где affinity_numeric удалось посчитать (не NaN)\n",
        "valid_stats = group_stats.dropna(subset=['affinity_range'])\n",
        "\n",
        "print(f\"Групп с валидными числовыми аффинитетами: {len(valid_stats)}\")\n",
        "print(f\"Средний разброс аффинитета в группе: {valid_stats['affinity_range'].mean():.4f}\")\n",
        "print(f\"Медианный разброс: {valid_stats['affinity_range'].median():.4f}\")\n",
        "print(f\"Максимальный разброс: {valid_stats['affinity_range'].max():.4f}\\n\")\n",
        "\n",
        "# Проверка на разные типы аффинитета в одной группе\n",
        "mixed_types = valid_stats[valid_stats['affinity_type_count'] > 1]\n",
        "if not mixed_types.empty:\n",
        "    print(f\"ВНИМАНИЕ: В {len(mixed_types)} группах смешаны разные типы аффинитета (сравнение может быть некорректным).\")\n",
        "else:\n",
        "    print(\"Типы аффинитета внутри каждой группы совпадают (корректно сравнивать числа).\\n\")\n",
        "\n",
        "# Топ-5 групп с самым большим разбросом\n",
        "print(\"=== ТОП-5 ГРУПП С САМЫМ БОЛЬШИМ РАЗБРОСОМ АФФИНИТЕТА ===\")\n",
        "top_diff_groups = valid_stats.nlargest(5, 'affinity_range')\n",
        "\n",
        "for idx, (indices, row) in enumerate(top_diff_groups.iterrows()):\n",
        "    heavy, light, antigen = indices\n",
        "    print(f\"\\nГруппа {idx+1} (разброс {row['affinity_range']:.4f}):\")\n",
        "    # Получаем строки этой группы\n",
        "    group_rows = analysis_df[\n",
        "        (analysis_df['heavy_sequence'] == heavy) & \n",
        "        (analysis_df['light_sequence'] == light) &\n",
        "        (analysis_df['antigen_sequence'] == antigen)\n",
        "    ]\n",
        "    display(group_rows[['dataset', 'affinity_type', 'affinity', 'confidence', 'processed_measurement']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31eb2693",
      "metadata": {},
      "source": [
        "#### Drop duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "2080d1a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер до удаления дубликатов: (401505, 11)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер после удаления дубликатов: (336257, 11)\n"
          ]
        }
      ],
      "source": [
        "# Удаляем дубликаты по heavy_sequence + light_sequence + antigen_sequence\n",
        "# Оставляем первую запись из каждой группы (affinity отличается, но это не важно)\n",
        "\n",
        "print(f\"Размер до удаления дубликатов: {agab_df.shape}\")\n",
        "\n",
        "agab_df = agab_df.drop_duplicates(\n",
        "    subset=['heavy_sequence', 'light_sequence', 'antigen_sequence'],\n",
        "    keep='first'\n",
        ")\n",
        "\n",
        "print(f\"Размер после удаления дубликатов: {agab_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44a4b1b",
      "metadata": {},
      "source": [
        "#### Анализ длинных и коротких антигенов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "c48a4f1e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    336257.00000\n",
              "mean        473.43476\n",
              "std         306.16660\n",
              "min          14.00000\n",
              "25%         318.00000\n",
              "50%         607.00000\n",
              "75%         607.00000\n",
              "max       34350.00000\n",
              "Name: antigen_sequence, dtype: float64"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agab_df['antigen_sequence'].str.len().describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3813d18",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "497"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agab_df[agab_df['antigen_sequence'].str.len() > 1000]['antigen_sequence'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "d900586d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ANALYSIS OF LONG ANTIGENS (> 1030 AA) ===\n",
            "\n",
            "Total records with long antigens: 2928\n",
            "Percentage of total dataset: 0.87%\n",
            "\n",
            "=== ANTIGEN LENGTH STATISTICS ===\n",
            "count     2928.000000\n",
            "mean      1877.172473\n",
            "std       1898.660162\n",
            "min       1032.000000\n",
            "25%       1210.000000\n",
            "50%       1321.000000\n",
            "75%       2165.000000\n",
            "max      34350.000000\n",
            "Name: antigen_length, dtype: float64\n",
            "\n",
            "Min length: 1032\n",
            "Max length: 34350\n",
            "Median length: 1321.0\n",
            "Mean length: 1877.2\n",
            "\n",
            "=== DISTRIBUTION BY DATASET ===\n",
            "dataset\n",
            "patents                    2264\n",
            "flab_shanehsazzadeh2023     341\n",
            "dlgo                        309\n",
            "genbank                       7\n",
            "skempiv2                      6\n",
            "structures-antibodies         1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique datasets: 6\n",
            "\n",
            "=== DISTRIBUTION BY AFFINITY TYPE ===\n",
            "affinity_type\n",
            "bool     2274\n",
            "kd        341\n",
            "ic_50     309\n",
            "ddg         4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique affinity types: 4\n",
            "\n",
            "=== UNIQUE ANTIGENS ===\n",
            "Unique antigen sequences: 479\n",
            "Average records per unique antigen: 6.11\n",
            "\n",
            "=== TOP 10 LONGEST ANTIGENS ===\n",
            "        dataset affinity_type  antigen_length confidence\n",
            "115955  patents          bool           34350     medium\n",
            "296830  patents          bool           34350     medium\n",
            "538053  patents          bool           34350     medium\n",
            "651556  patents          bool           34350     medium\n",
            "653675  patents          bool           34350     medium\n",
            "530675  patents          bool           15639     medium\n",
            "176239  patents          bool           14507     medium\n",
            "296380  patents          bool           14507     medium\n",
            "420720  patents          bool           14507     medium\n",
            "471769  patents          bool           14507     medium\n",
            "\n",
            "=== METADATA ANALYSIS ===\n",
            "Records with metadata: 2928 (100.0%)\n",
            "\n",
            "=== SAMPLE RECORDS (first 5) ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>antigen_length</th>\n",
              "      <th>confidence</th>\n",
              "      <th>scfv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>skempiv2</td>\n",
              "      <td>ddg</td>\n",
              "      <td>1267</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48243</th>\n",
              "      <td>dlgo</td>\n",
              "      <td>ic_50</td>\n",
              "      <td>1283</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48244</th>\n",
              "      <td>dlgo</td>\n",
              "      <td>ic_50</td>\n",
              "      <td>1283</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48245</th>\n",
              "      <td>dlgo</td>\n",
              "      <td>ic_50</td>\n",
              "      <td>1283</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48246</th>\n",
              "      <td>dlgo</td>\n",
              "      <td>ic_50</td>\n",
              "      <td>1283</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dataset affinity_type  antigen_length confidence   scfv\n",
              "12     skempiv2           ddg            1267  very_high  False\n",
              "48243      dlgo         ic_50            1283  very_high  False\n",
              "48244      dlgo         ic_50            1283  very_high  False\n",
              "48245      dlgo         ic_50            1283  very_high  False\n",
              "48246      dlgo         ic_50            1283  very_high  False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#### Analysis of Long Antigens (>700 AA)\n",
        "\n",
        "# Filter for long antigens\n",
        "long_antigen_threshold = 1030\n",
        "long_antigens_df = agab_df[agab_df['antigen_sequence'].str.len() > long_antigen_threshold].copy()\n",
        "\n",
        "print(f\"=== ANALYSIS OF LONG ANTIGENS (> {long_antigen_threshold} AA) ===\\n\")\n",
        "print(f\"Total records with long antigens: {len(long_antigens_df)}\")\n",
        "print(f\"Percentage of total dataset: {len(long_antigens_df) / len(agab_df) * 100:.2f}%\\n\")\n",
        "\n",
        "# Add antigen length column for analysis\n",
        "long_antigens_df['antigen_length'] = long_antigens_df['antigen_sequence'].str.len()\n",
        "\n",
        "# Basic statistics\n",
        "print(\"=== ANTIGEN LENGTH STATISTICS ===\")\n",
        "print(long_antigens_df['antigen_length'].describe())\n",
        "print(f\"\\nMin length: {long_antigens_df['antigen_length'].min()}\")\n",
        "print(f\"Max length: {long_antigens_df['antigen_length'].max()}\")\n",
        "print(f\"Median length: {long_antigens_df['antigen_length'].median():.1f}\")\n",
        "print(f\"Mean length: {long_antigens_df['antigen_length'].mean():.1f}\\n\")\n",
        "\n",
        "# Distribution by dataset\n",
        "print(\"=== DISTRIBUTION BY DATASET ===\")\n",
        "dataset_counts = long_antigens_df['dataset'].value_counts()\n",
        "print(dataset_counts)\n",
        "print(f\"\\nUnique datasets: {long_antigens_df['dataset'].nunique()}\\n\")\n",
        "\n",
        "# Distribution by affinity_type\n",
        "print(\"=== DISTRIBUTION BY AFFINITY TYPE ===\")\n",
        "affinity_counts = long_antigens_df['affinity_type'].value_counts()\n",
        "print(affinity_counts)\n",
        "print(f\"\\nUnique affinity types: {long_antigens_df['affinity_type'].nunique()}\\n\")\n",
        "\n",
        "# Unique antigens\n",
        "print(\"=== UNIQUE ANTIGENS ===\")\n",
        "unique_antigens = long_antigens_df['antigen_sequence'].nunique()\n",
        "print(f\"Unique antigen sequences: {unique_antigens}\")\n",
        "print(f\"Average records per unique antigen: {len(long_antigens_df) / unique_antigens:.2f}\\n\")\n",
        "\n",
        "# Sample of longest antigens\n",
        "print(\"=== TOP 10 LONGEST ANTIGENS ===\")\n",
        "top_longest = long_antigens_df.nlargest(10, 'antigen_length')[\n",
        "    ['dataset', 'affinity_type', 'antigen_length', 'confidence']\n",
        "]\n",
        "print(top_longest)\n",
        "print()\n",
        "\n",
        "# Check for patterns in metadata if available\n",
        "if 'metadata' in long_antigens_df.columns:\n",
        "    print(\"=== METADATA ANALYSIS ===\")\n",
        "    non_null_metadata = long_antigens_df['metadata'].notna().sum()\n",
        "    print(f\"Records with metadata: {non_null_metadata} ({non_null_metadata / len(long_antigens_df) * 100:.1f}%)\")\n",
        "    print()\n",
        "\n",
        "# Display sample records\n",
        "print(\"=== SAMPLE RECORDS (first 5) ===\")\n",
        "sample_cols = ['dataset', 'affinity_type', 'antigen_length', 'confidence', 'scfv']\n",
        "display_cols = [col for col in sample_cols if col in long_antigens_df.columns]\n",
        "display(long_antigens_df[display_cols].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd1b0875",
      "metadata": {},
      "source": [
        "Сделаем фильтр до 1000 аминокислот. Нужно обосновать это так, что во-первых мы будем тюнить с не очень большим кол-вом параметров и данных в целом, поэтому слишком длинные антигены будут для модели скорее каким-то шумом. Помимо этого, мы будем подавать сиквенс как эмбеддинг скорее всего ESM-модели, а у них есть ограничение на длину белка. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f58b43",
      "metadata": {},
      "source": [
        "Для коротких тоже какой-нибудь порог типа 30 АК"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf36bed",
      "metadata": {},
      "source": [
        "#### ANARCI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "112571c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scFv всего: 55670\n",
            "оба домена уже раздельно: 0\n",
            "только heavy заполнен: 55670\n",
            "только light заполнен: 0\n",
            "оба пустые: 0\n"
          ]
        }
      ],
      "source": [
        "def is_empty(x):\n",
        "    return x is None or (isinstance(x, float) and np.isnan(x)) or (isinstance(x, str) and x.strip() == \"\")\n",
        "\n",
        "scfv_df = agab_df[agab_df['scfv'] == True].copy()\n",
        "\n",
        "# сколько scFv-строк уже имеют обе цепи\n",
        "both_present = (~scfv_df[\"heavy_sequence\"].apply(is_empty)) & (~scfv_df[\"light_sequence\"].apply(is_empty))\n",
        "only_heavy   = (~scfv_df[\"heavy_sequence\"].apply(is_empty)) & ( scfv_df[\"light_sequence\"].apply(is_empty))\n",
        "only_light   = ( scfv_df[\"heavy_sequence\"].apply(is_empty)) & (~scfv_df[\"light_sequence\"].apply(is_empty))\n",
        "\n",
        "print(\"scFv всего:\", len(scfv_df))\n",
        "print(\"оба домена уже раздельно:\", both_present.sum())\n",
        "print(\"только heavy заполнен:\", only_heavy.sum())\n",
        "print(\"только light заполнен:\", only_light.sum())\n",
        "print(\"оба пустые:\", ((~both_present) & (~only_heavy) & (~only_light)).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a3fdbd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing sequences...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f5ed7450bc5413ebfedceee4307fe75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Collecting sequences:   0%|          | 0/337196 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running ANARCI on 620789 sequences using 16 processes...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c6c43bb027a486492ada82af0def97c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ANARCI Parallel:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ANARCI results...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b6e8dd571c44f3f97f8473ee31a4c3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing results:   0%|          | 0/620789 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updating DataFrame columns...\n",
            "Extraction complete. Found 337196 Heavy chains and 337196 Light chains.\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add current directory to path to import worker module\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.append(os.getcwd())\n",
        "\n",
        "# Import worker function from external file to fix pickling error\n",
        "try:\n",
        "    from data.anarci_worker import run_anarci_batch\n",
        "except ImportError:\n",
        "    # Fallback if running from data directory directly\n",
        "    try:\n",
        "        from anarci_worker import run_anarci_batch\n",
        "    except ImportError:\n",
        "        print(\"Error: Could not import anarci_worker. Make sure data/anarci_worker.py exists.\")\n",
        "\n",
        "def process_antibody_sequences_optimized(df, n_jobs=8, batch_size=5000):\n",
        "    \"\"\"\n",
        "    Optimized version of antibody processing using multiprocessing.\n",
        "    Runs ANARCI in parallel batches and minimizes DataFrame operations.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # 1. Prepare sequences list efficiently\n",
        "    print(\"Preparing sequences...\")\n",
        "    sequences_to_anarci = []\n",
        "    mapping_list = [] \n",
        "    \n",
        "    rows_iter = zip(df.index, df['scfv'], df['heavy_sequence'], df['light_sequence'])\n",
        "    \n",
        "    for idx, is_scfv, h_seq, l_seq in tqdm(rows_iter, total=len(df), desc=\"Collecting sequences\"):\n",
        "        if is_scfv:\n",
        "            seq = h_seq\n",
        "            if pd.isna(seq) or len(seq) == 0:\n",
        "                 seq = l_seq if isinstance(l_seq, str) else ''\n",
        "            \n",
        "            if isinstance(seq, str) and len(seq) > 0:\n",
        "                internal_id = f\"{idx}_scfv\"\n",
        "                sequences_to_anarci.append((internal_id, seq))\n",
        "                mapping_list.append((idx, 'scfv', seq))\n",
        "        else:\n",
        "            if isinstance(h_seq, str) and len(h_seq) > 0:\n",
        "                internal_id = f\"{idx}_heavy\"\n",
        "                sequences_to_anarci.append((internal_id, h_seq))\n",
        "                mapping_list.append((idx, 'heavy', h_seq))\n",
        "            \n",
        "            if isinstance(l_seq, str) and len(l_seq) > 0:\n",
        "                internal_id = f\"{idx}_light\"\n",
        "                sequences_to_anarci.append((internal_id, l_seq))\n",
        "                mapping_list.append((idx, 'light', l_seq))\n",
        "                \n",
        "    total_seqs = len(sequences_to_anarci)\n",
        "    print(f\"Running ANARCI on {total_seqs} sequences using {n_jobs} processes...\")\n",
        "    \n",
        "    # 2. Parallel execution\n",
        "    chunk_size = min(batch_size, max(1, total_seqs // (n_jobs * 2)))\n",
        "    chunks = [sequences_to_anarci[i : i + chunk_size] for i in range(0, total_seqs, chunk_size)]\n",
        "    \n",
        "    all_numbering = []\n",
        "    all_alignment_details = []\n",
        "    \n",
        "    with Pool(processes=n_jobs) as pool:\n",
        "        results = list(tqdm(pool.imap(run_anarci_batch, chunks), total=len(chunks), desc=\"ANARCI Parallel\"))\n",
        "    \n",
        "    # Unpack results\n",
        "    for num, aln, err in results:\n",
        "        if err and not isinstance(err, str): \n",
        "             pass\n",
        "        if num is None:\n",
        "            print(f\"Batch failed: {err}\")\n",
        "            continue \n",
        "        all_numbering.extend(num)\n",
        "        all_alignment_details.extend(aln)\n",
        "\n",
        "    # 3. Process results efficiently\n",
        "    print(\"Processing ANARCI results...\")\n",
        "    \n",
        "    heavy_seqs = {}\n",
        "    light_seqs = {}\n",
        "    heavy_specs = {}\n",
        "    light_specs = {}\n",
        "    heavy_germs = {}\n",
        "    light_germs = {}\n",
        "    heavy_nums = {}\n",
        "    light_nums = {}\n",
        "    \n",
        "    for i, (num_hits, hits) in tqdm(enumerate(zip(all_numbering, all_alignment_details)), total=len(all_numbering), desc=\"Parsing results\"):\n",
        "        if not hits or not num_hits: \n",
        "            continue\n",
        "            \n",
        "        original_idx, seq_type, full_seq = mapping_list[i]\n",
        "        \n",
        "        for domain_idx, hit in enumerate(hits):\n",
        "            if not hit: continue\n",
        "            \n",
        "            chain_type = hit.get('chain_type', 'unknown')\n",
        "            start = hit.get('query_start')\n",
        "            end = hit.get('query_end')\n",
        "            species = hit.get('species')\n",
        "            germlines = hit.get('germlines')\n",
        "            \n",
        "            domain_data = num_hits[domain_idx]\n",
        "            numbering_json = None\n",
        "            if domain_data:\n",
        "                residues_json = [\n",
        "                    {\"pos\": r[0][0], \"ins\": r[0][1].strip(), \"aa\": r[1]}\n",
        "                    for r in domain_data[0]\n",
        "                ]\n",
        "                numbering_obj = {\n",
        "                    \"domain_start\": domain_data[1],\n",
        "                    \"domain_end\": domain_data[2],\n",
        "                    \"residues\": residues_json\n",
        "                }\n",
        "                numbering_json = json.dumps([numbering_obj])\n",
        "            \n",
        "            domain_seq = full_seq[start : end] if (start is not None and end is not None) else None\n",
        "\n",
        "            is_heavy = False\n",
        "            if seq_type == 'scfv':\n",
        "                if chain_type == 'H': is_heavy = True\n",
        "                elif chain_type in ['K', 'L']: is_heavy = False\n",
        "                else: continue\n",
        "            elif seq_type == 'heavy':\n",
        "                if chain_type == 'H': is_heavy = True\n",
        "                else: continue\n",
        "            elif seq_type == 'light':\n",
        "                if chain_type in ['K', 'L']: is_heavy = False\n",
        "                else: continue\n",
        "            \n",
        "            if is_heavy:\n",
        "                heavy_seqs[original_idx] = domain_seq\n",
        "                heavy_specs[original_idx] = species\n",
        "                heavy_germs[original_idx] = str(germlines)\n",
        "                heavy_nums[original_idx] = numbering_json\n",
        "            else:\n",
        "                light_seqs[original_idx] = domain_seq\n",
        "                light_specs[original_idx] = species\n",
        "                light_germs[original_idx] = str(germlines)\n",
        "                light_nums[original_idx] = numbering_json\n",
        "\n",
        "    print(\"Updating DataFrame columns...\")\n",
        "    \n",
        "    # Convert dictionaries to Series once\n",
        "    heavy_seqs_series = pd.Series(heavy_seqs, name='heavy_sequence')\n",
        "    light_seqs_series = pd.Series(light_seqs, name='light_sequence')\n",
        "    \n",
        "    # Use combine_first to update only found values\n",
        "    # heavy_seqs_series contains only updated sequences, combine_first fills gaps from original\n",
        "    df['heavy_sequence'] = heavy_seqs_series.combine_first(df['heavy_sequence'])\n",
        "    df['light_sequence'] = light_seqs_series.combine_first(df['light_sequence'])\n",
        "    \n",
        "    # For new columns, map is fine as they are empty or overwritten\n",
        "    df['heavy_species'] = df.index.map(heavy_specs)\n",
        "    df['light_species'] = df.index.map(light_specs)\n",
        "    df['heavy_germlines'] = df.index.map(heavy_germs)\n",
        "    df['light_germlines'] = df.index.map(light_germs)\n",
        "    df['heavy_numbering'] = df.index.map(heavy_nums)\n",
        "    df['light_numbering'] = df.index.map(light_nums)\n",
        "    found_h = df['heavy_sequence'].notna().sum()\n",
        "    found_l = df['light_sequence'].notna().sum()\n",
        "    print(f\"Extraction complete. Found {found_h} Heavy chains and {found_l} Light chains.\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply the optimized function\n",
        "if __name__ == '__main__':\n",
        "    agab_df = process_antibody_sequences_optimized(agab_df, n_jobs=16)\n",
        "\n",
        "\n",
        "# Сохраняем датафрейм в .parquet\n",
        "output_path = 'agab_after_anarci.parquet'\n",
        "df = agab_df\n",
        "\n",
        "# Fix mixed types for Parquet export\n",
        "# 'affinity' contains both numbers and strings (e.g. 'h'), so we must save as string\n",
        "df['affinity'] = df['affinity'].astype(str)\n",
        "df['processed_measurement'] = df['processed_measurement'].astype(str)\n",
        "\n",
        "df.to_parquet(output_path, index=False, engine='pyarrow')\n",
        "print(f\"Отфильтрованные данные сохранены в {output_path}\")\n",
        "print(f\"Размер сохраненных данных: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1432b436",
      "metadata": {},
      "source": [
        "### Фильтрация после ANARCI разметки\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03fbf0a",
      "metadata": {},
      "source": [
        "Ответ на вопрос про антитела > 140 а.к.\n",
        "Стоит ли их оставлять?\n",
        "Да, однозначно стоит, но с проверкой.\n",
        "Длинные последовательности (>140 а.к.) в большинстве случаев — это не ошибка, а антитела с ультра-длинным CDRH3 (петлей, связывающей антиген). Такие антитела встречаются в природе (например, у ВИЧ-инфицированных пациентов или у некоторых видов животных, таких как коровы) и могут обладать уникальными свойствами нейтрализации.\n",
        "Если вы удалите их просто по порогу длины, вы потеряете самые интересные и редкие данные. Проверка совокупной длины CDR — отличная идея, чтобы убедиться, что \"лишняя\" длина находится именно в вариабельных петлях (где ей и место), а не в каркасных регионах (что было бы ошибкой секвенирования)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3954578a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Всего записей: (337196, 17)\n"
          ]
        }
      ],
      "source": [
        "agab_df = pd.read_parquet('agab_after_anarci.parquet')\n",
        "print(f\"Всего записей: {agab_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73936952",
      "metadata": {},
      "source": [
        "CDR3 <= 37: \"У тебя не может быть одной петли длиной в километр\".  \n",
        "\n",
        "total_cdr_len: \"Если ты в целом длинный гигант, докажи это длиной своих петель, а не ошибкой в каркасе\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "db0c45ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ИСХОДНЫЙ размер датасета: 337196\n",
            "\n",
            "[Шаг 1/3] Проверка консервативных цистеинов (C23 + C104)...\n",
            "   -> Осталось: 336751\n",
            "   -> Удалено: 445 (отсутствуют критические цистеины)\n",
            "\n",
            "[Шаг 2/3] Проверка длины CDR3 (порог OAS: <= 37 а.к.)...\n",
            "   -> Осталось: 336741\n",
            "   -> Удалено: 10 (CDR3 > 37 аминокислот)\n",
            "\n",
            "[Шаг 3/3] Анализ сверхдлинных цепей (>140 а.к.)...\n",
            "   -> Длинных цепей (>140 а.к.) не обнаружено. Пропуск шага.\n",
            "\n",
            "=== ИТОГ ===\n",
            "Финальный размер: 336741\n",
            "Всего удалено: 455\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# --- Функции --- (те же самые, без изменений)\n",
        "def has_conservative_cysteines(numbering_json):\n",
        "    if not numbering_json or pd.isna(numbering_json):\n",
        "        return False\n",
        "    try:\n",
        "        data = json.loads(numbering_json)\n",
        "        if not data: return False\n",
        "        residues = data[0].get('residues', [])\n",
        "        has_c23 = any(r['pos'] == 23 and r['aa'] == 'C' for r in residues)\n",
        "        has_c104 = any(r['pos'] == 104 and r['aa'] == 'C' for r in residues)\n",
        "        return has_c23 and has_c104\n",
        "    except: return False\n",
        "\n",
        "def check_cdr3_length(numbering_json, threshold=37):\n",
        "    if not numbering_json or pd.isna(numbering_json): return False\n",
        "    try:\n",
        "        data = json.loads(numbering_json)\n",
        "        if not data: return False\n",
        "        residues = data[0].get('residues', [])\n",
        "        cdr3_len = sum(1 for r in residues if 105 <= r['pos'] <= 117)\n",
        "        return cdr3_len <= threshold\n",
        "    except: return False\n",
        "\n",
        "def get_total_cdr_length(numbering_json):\n",
        "    if not numbering_json or pd.isna(numbering_json): return 0\n",
        "    try:\n",
        "        data = json.loads(numbering_json)\n",
        "        if not data: return 0\n",
        "        residues = data[0].get('residues', [])\n",
        "        cdr_len = 0\n",
        "        for r in residues:\n",
        "            p = int(r['pos'])\n",
        "            if (27 <= p <= 38) or (56 <= p <= 65) or (105 <= p <= 117):\n",
        "                cdr_len += 1\n",
        "        return cdr_len\n",
        "    except: return 0\n",
        "\n",
        "# === ПРИМЕНЕНИЕ ФИЛЬТРОВ ===\n",
        "\n",
        "print(f\"ИСХОДНЫЙ размер датасета: {len(agab_df)}\")\n",
        "current_df = agab_df.copy()\n",
        "\n",
        "# --- ШАГ 1: Фильтрация по цистеинам (C23 & C104) ---\n",
        "print(\"\\n[Шаг 1/3] Проверка консервативных цистеинов (C23 + C104)...\")\n",
        "if 'heavy_cys_ok' not in current_df.columns:\n",
        "    current_df['heavy_cys_ok'] = current_df['heavy_numbering'].apply(has_conservative_cysteines)\n",
        "    current_df['light_cys_ok'] = current_df['light_numbering'].apply(has_conservative_cysteines)\n",
        "\n",
        "h_cys = current_df['heavy_sequence'].isna() | current_df['heavy_cys_ok']\n",
        "l_cys = current_df['light_sequence'].isna() | current_df['light_cys_ok']\n",
        "not_empty = current_df['heavy_sequence'].notna() | current_df['light_sequence'].notna()\n",
        "\n",
        "before_len = len(current_df)\n",
        "current_df = current_df[h_cys & l_cys & not_empty]\n",
        "removed_cys = before_len - len(current_df)\n",
        "\n",
        "print(f\"   -> Осталось: {len(current_df)}\")\n",
        "print(f\"   -> Удалено: {removed_cys} (отсутствуют критические цистеины)\")\n",
        "\n",
        "\n",
        "# --- ШАГ 2: Фильтрация по длине CDR3 (<= 37 а.к.) ---\n",
        "print(\"\\n[Шаг 2/3] Проверка длины CDR3 (порог OAS: <= 37 а.к.)...\")\n",
        "current_df['heavy_cdr3_ok'] = current_df['heavy_numbering'].apply(check_cdr3_length)\n",
        "current_df['light_cdr3_ok'] = current_df['light_numbering'].apply(check_cdr3_length)\n",
        "\n",
        "h_cdr3 = current_df['heavy_sequence'].isna() | current_df['heavy_cdr3_ok']\n",
        "l_cdr3 = current_df['light_sequence'].isna() | current_df['light_cdr3_ok']\n",
        "\n",
        "before_len = len(current_df)\n",
        "current_df = current_df[h_cdr3 & l_cdr3]\n",
        "removed_cdr3 = before_len - len(current_df)\n",
        "\n",
        "print(f\"   -> Осталось: {len(current_df)}\")\n",
        "print(f\"   -> Удалено: {removed_cdr3} (CDR3 > 37 аминокислот)\")\n",
        "\n",
        "\n",
        "# --- ШАГ 3: Проверка длинных последовательностей (>140 а.к.) ---\n",
        "print(\"\\n[Шаг 3/3] Анализ сверхдлинных цепей (>140 а.к.)...\")\n",
        "current_df['heavy_len'] = current_df['heavy_sequence'].str.len().fillna(0)\n",
        "long_mask = current_df['heavy_len'] > 140\n",
        "\n",
        "long_count = long_mask.sum()\n",
        "if long_count > 0:\n",
        "    print(f\"   Найдено длинных цепей (>140): {long_count}\")\n",
        "    \n",
        "    # Считаем сумму длин CDR только для длинных цепей\n",
        "    current_df.loc[long_mask, 'total_cdr_len'] = current_df.loc[long_mask, 'heavy_numbering'].apply(get_total_cdr_length)\n",
        "    \n",
        "    # Условие удаления: Длинная цепь (>140) НО короткие CDR (<35)\n",
        "    # Это значит, что длина набрана за счет каркаса (ошибка)\n",
        "    suspicious_mask = long_mask & (current_df['total_cdr_len'] < 35)\n",
        "    suspicious_count = suspicious_mask.sum()\n",
        "    \n",
        "    if suspicious_count > 0:\n",
        "        before_len = len(current_df)\n",
        "        current_df = current_df[~suspicious_mask]\n",
        "        print(f\"   -> Удалено: {suspicious_count} (длинные цепи с подозрительно короткими CDR)\")\n",
        "    else:\n",
        "        print(\"   -> Удалено: 0 (все длинные цепи имеют адекватно длинные CDR)\")\n",
        "else:\n",
        "    print(\"   -> Длинных цепей (>140 а.к.) не обнаружено. Пропуск шага.\")\n",
        "\n",
        "# Удаляем технические колонки перед сохранением\n",
        "cols_to_drop = ['heavy_cys_ok', 'light_cys_ok', 'heavy_cdr3_ok', 'light_cdr3_ok', 'total_cdr_len', 'heavy_len']\n",
        "agab_filtered = current_df.drop(columns=cols_to_drop, errors='ignore').copy()\n",
        "\n",
        "print(f\"\\n=== ИТОГ ===\")\n",
        "print(f\"Финальный размер: {len(agab_filtered)}\")\n",
        "print(f\"Всего удалено: {len(agab_df) - len(agab_filtered)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc37a4bf",
      "metadata": {},
      "source": [
        "### Save to agab.parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "80ed7ead",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Отфильтрованные данные сохранены в agab.parquet\n",
            "Размер сохраненных данных: (336741, 17)\n"
          ]
        }
      ],
      "source": [
        "# Сохраняем датафрейм в .parquet\n",
        "output_path = 'agab.parquet'\n",
        "df = agab_filtered\n",
        "\n",
        "# Fix mixed types for Parquet export\n",
        "# 'affinity' contains both numbers and strings (e.g. 'h'), so we must save as string\n",
        "df['affinity'] = df['affinity'].astype(str)\n",
        "df['processed_measurement'] = df['processed_measurement'].astype(str)\n",
        "\n",
        "df.to_parquet(output_path, index=False, engine='pyarrow')\n",
        "print(f\"Отфильтрованные данные сохранены в {output_path}\")\n",
        "print(f\"Размер сохраненных данных: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bb4a2b",
      "metadata": {},
      "source": [
        "### Делим на train test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30619b6",
      "metadata": {},
      "source": [
        "сделаем разбиение данных в два этапа:\n",
        "1) easy-cluster на антигенах с --min-seq-id 0.4, --cov-mode 2, -c 0.7. Рандомно поделим КЛАСТЕРЫ на train и test, чтобы примерно соблюсти 80/20 соотношение (по уникальным антигенам, не по числу строк в датасете, т.к. все равно потом будем бороться с дисбалансом) \n",
        "2) easy-search: train против test с теми же параметрами. Если кто-то из test оказывается похож на train, переносим его из test в train и повторяем шаг (2) полностью, пока похожие не перестанут находиться\n",
        "3) easy-search: train против test уже на антителах, --min-seq-id 0.7. (т.к. CDR занимают) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "76e21e72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загружено: (336741, 18)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загружаем из agab_mmseq.parquet\n",
        "agab_mmseq = pd.read_parquet('agab_mmseq.parquet', engine='pyarrow')\n",
        "print(f\"Загружено: {agab_mmseq.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c6a1bac1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>heavy_sequence</th>\n",
              "      <th>light_sequence</th>\n",
              "      <th>scfv</th>\n",
              "      <th>affinity_type</th>\n",
              "      <th>affinity</th>\n",
              "      <th>antigen_sequence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>nanobody</th>\n",
              "      <th>metadata</th>\n",
              "      <th>processed_measurement</th>\n",
              "      <th>heavy_species</th>\n",
              "      <th>light_species</th>\n",
              "      <th>heavy_germlines</th>\n",
              "      <th>light_germlines</th>\n",
              "      <th>heavy_numbering</th>\n",
              "      <th>light_numbering</th>\n",
              "      <th>mmseq_cluster_rep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abdesign</td>\n",
              "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTSYWINWVRQAPGQGLE...</td>\n",
              "      <td>DIVMTQSPDSLAVSLGERATINCKSSQSLWDSGNQKNFLTWYQQKP...</td>\n",
              "      <td>False</td>\n",
              "      <td>elisa_mut_to_wt_ratio</td>\n",
              "      <td>1.008535785</td>\n",
              "      <td>WNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQTD...</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "      <td>{'heavy_riot_numbering': {'cdr1_aa': 'GYTFTSYW...</td>\n",
              "      <td>1.008535785</td>\n",
              "      <td>mouse</td>\n",
              "      <td>human</td>\n",
              "      <td>{'v_gene': [('human', 'IGHV1-46*01'), 0.857142...</td>\n",
              "      <td>{'v_gene': [('human', 'IGKV4-1*01'), 0.8877551...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 116, \"resid...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 112, \"resid...</td>\n",
              "      <td>HHHHHHGENLYFQGSLDSPDRPWNPPTFSPALLVVTEGDNATFTCS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abdesign</td>\n",
              "      <td>VQLVQSGVEVKKPGASVKVSCKASGYTFTNYYMYWVRQAPGQGLEW...</td>\n",
              "      <td>EIVLTQSPATLSLSPGERATLSCRASKGVSTSGYSYLHWYQQKPGQ...</td>\n",
              "      <td>False</td>\n",
              "      <td>elisa_mut_to_wt_ratio</td>\n",
              "      <td>1.052205794</td>\n",
              "      <td>PWNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQT...</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "      <td>{'heavy_riot_numbering': {'cdr1_aa': 'GYTFTNYY...</td>\n",
              "      <td>1.052205794</td>\n",
              "      <td>mouse</td>\n",
              "      <td>human</td>\n",
              "      <td>{'v_gene': [('human', 'IGHV1-2*02'), 0.7857142...</td>\n",
              "      <td>{'v_gene': [('human', 'IGKV3-11*01'), 0.858695...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 118, \"resid...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 110, \"resid...</td>\n",
              "      <td>HHHHHHGENLYFQGSLDSPDRPWNPPTFSPALLVVTEGDNATFTCS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>structures-antibodies</td>\n",
              "      <td>QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLE...</td>\n",
              "      <td>DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRL...</td>\n",
              "      <td>False</td>\n",
              "      <td>bool</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SALHWRAAGAATVLLVIVLLAGSYLAVLAERGAPGAQLITYPRALW...</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "      <td>{'heavy_riot_numbering': {'cdr1_aa': 'GYTFTSDW...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>mouse</td>\n",
              "      <td>mouse</td>\n",
              "      <td>{'v_gene': [('mouse', 'IGHV1-69-5*01'), 0.8877...</td>\n",
              "      <td>{'v_gene': [('mouse', 'IGKV5-48*01'), 0.978260...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 117, \"resid...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 106, \"resid...</td>\n",
              "      <td>MAPMLSGLLARLVKLLLGRHGSALHWRAAGAATVLLVIVLLAGSYL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>structures-antibodies</td>\n",
              "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFDDYSMNWVRQAPGKGLE...</td>\n",
              "      <td>DIQLTQSPSSLSASVGDRVTITCQASQDISNYLNWYQQKPGKAPKL...</td>\n",
              "      <td>False</td>\n",
              "      <td>bool</td>\n",
              "      <td>1.0</td>\n",
              "      <td>FKVATPYSLYVCPEGQNVTLTCRLLGPVDKGHDVTFYKTWYRSSRG...</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "      <td>{'heavy_riot_numbering': {'cdr1_aa': 'GFTFDDYS...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>human</td>\n",
              "      <td>human</td>\n",
              "      <td>{'v_gene': [('human', 'IGHV3-48*01'), 0.948979...</td>\n",
              "      <td>{'v_gene': [('human', 'IGKV1-33*01'), 0.967391...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 121, \"resid...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 107, \"resid...</td>\n",
              "      <td>FKVATPYSLYVCPEGQNVTLTCRLLGPVDKGHDVTFYKTWYRSSRG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>structures-antibodies</td>\n",
              "      <td>VKLQESGAVVQPGGSLRLSCAASGFTGSDYDMSWIRQAPGKGLEWV...</td>\n",
              "      <td>DIQMTQSPASLAVSPGQRATITCRASESVSNYGINFINWFQQKPGQ...</td>\n",
              "      <td>False</td>\n",
              "      <td>bool</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ADPGYLLEFDTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...</td>\n",
              "      <td>very_high</td>\n",
              "      <td>False</td>\n",
              "      <td>{'heavy_riot_numbering': {'cdr1_aa': 'GFTGSDYD...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>human</td>\n",
              "      <td>mouse</td>\n",
              "      <td>{'v_gene': [('human', 'IGHV3-66*01'), 0.773195...</td>\n",
              "      <td>{'v_gene': [('mouse', 'IGKV3-2*01'), 0.8020833...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 119, \"resid...</td>\n",
              "      <td>[{\"domain_start\": 0, \"domain_end\": 110, \"resid...</td>\n",
              "      <td>MEEIVLLFAIVSLARSDQICIGYHANNSTKQVDTIMEKNVTVTHAQ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 dataset                                     heavy_sequence  \\\n",
              "0               abdesign  QVQLVQSGAEVKKPGASVKVSCKASGYTFTSYWINWVRQAPGQGLE...   \n",
              "1               abdesign  VQLVQSGVEVKKPGASVKVSCKASGYTFTNYYMYWVRQAPGQGLEW...   \n",
              "2  structures-antibodies  QVQLQQPGAELVKPGASVKLSCKASGYTFTSDWIHWVKQRPGHGLE...   \n",
              "3  structures-antibodies  EVQLVESGGGLVQPGGSLRLSCAASGFTFDDYSMNWVRQAPGKGLE...   \n",
              "4  structures-antibodies  VKLQESGAVVQPGGSLRLSCAASGFTGSDYDMSWIRQAPGKGLEWV...   \n",
              "\n",
              "                                      light_sequence   scfv  \\\n",
              "0  DIVMTQSPDSLAVSLGERATINCKSSQSLWDSGNQKNFLTWYQQKP...  False   \n",
              "1  EIVLTQSPATLSLSPGERATLSCRASKGVSTSGYSYLHWYQQKPGQ...  False   \n",
              "2  DILLTQSPAILSVSPGERVSFSCRASQSIGTDIHWYQQRTNGSPRL...  False   \n",
              "3  DIQLTQSPSSLSASVGDRVTITCQASQDISNYLNWYQQKPGKAPKL...  False   \n",
              "4  DIQMTQSPASLAVSPGQRATITCRASESVSNYGINFINWFQQKPGQ...  False   \n",
              "\n",
              "           affinity_type     affinity  \\\n",
              "0  elisa_mut_to_wt_ratio  1.008535785   \n",
              "1  elisa_mut_to_wt_ratio  1.052205794   \n",
              "2                   bool          1.0   \n",
              "3                   bool          1.0   \n",
              "4                   bool          1.0   \n",
              "\n",
              "                                    antigen_sequence confidence  nanobody  \\\n",
              "0  WNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQTD...  very_high     False   \n",
              "1  PWNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQT...  very_high     False   \n",
              "2  SALHWRAAGAATVLLVIVLLAGSYLAVLAERGAPGAQLITYPRALW...  very_high     False   \n",
              "3  FKVATPYSLYVCPEGQNVTLTCRLLGPVDKGHDVTFYKTWYRSSRG...  very_high     False   \n",
              "4  ADPGYLLEFDTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...  very_high     False   \n",
              "\n",
              "                                            metadata processed_measurement  \\\n",
              "0  {'heavy_riot_numbering': {'cdr1_aa': 'GYTFTSYW...           1.008535785   \n",
              "1  {'heavy_riot_numbering': {'cdr1_aa': 'GYTFTNYY...           1.052205794   \n",
              "2  {'heavy_riot_numbering': {'cdr1_aa': 'GYTFTSDW...                   1.0   \n",
              "3  {'heavy_riot_numbering': {'cdr1_aa': 'GFTFDDYS...                   1.0   \n",
              "4  {'heavy_riot_numbering': {'cdr1_aa': 'GFTGSDYD...                   1.0   \n",
              "\n",
              "  heavy_species light_species  \\\n",
              "0         mouse         human   \n",
              "1         mouse         human   \n",
              "2         mouse         mouse   \n",
              "3         human         human   \n",
              "4         human         mouse   \n",
              "\n",
              "                                     heavy_germlines  \\\n",
              "0  {'v_gene': [('human', 'IGHV1-46*01'), 0.857142...   \n",
              "1  {'v_gene': [('human', 'IGHV1-2*02'), 0.7857142...   \n",
              "2  {'v_gene': [('mouse', 'IGHV1-69-5*01'), 0.8877...   \n",
              "3  {'v_gene': [('human', 'IGHV3-48*01'), 0.948979...   \n",
              "4  {'v_gene': [('human', 'IGHV3-66*01'), 0.773195...   \n",
              "\n",
              "                                     light_germlines  \\\n",
              "0  {'v_gene': [('human', 'IGKV4-1*01'), 0.8877551...   \n",
              "1  {'v_gene': [('human', 'IGKV3-11*01'), 0.858695...   \n",
              "2  {'v_gene': [('mouse', 'IGKV5-48*01'), 0.978260...   \n",
              "3  {'v_gene': [('human', 'IGKV1-33*01'), 0.967391...   \n",
              "4  {'v_gene': [('mouse', 'IGKV3-2*01'), 0.8020833...   \n",
              "\n",
              "                                     heavy_numbering  \\\n",
              "0  [{\"domain_start\": 0, \"domain_end\": 116, \"resid...   \n",
              "1  [{\"domain_start\": 0, \"domain_end\": 118, \"resid...   \n",
              "2  [{\"domain_start\": 0, \"domain_end\": 117, \"resid...   \n",
              "3  [{\"domain_start\": 0, \"domain_end\": 121, \"resid...   \n",
              "4  [{\"domain_start\": 0, \"domain_end\": 119, \"resid...   \n",
              "\n",
              "                                     light_numbering  \\\n",
              "0  [{\"domain_start\": 0, \"domain_end\": 112, \"resid...   \n",
              "1  [{\"domain_start\": 0, \"domain_end\": 110, \"resid...   \n",
              "2  [{\"domain_start\": 0, \"domain_end\": 106, \"resid...   \n",
              "3  [{\"domain_start\": 0, \"domain_end\": 107, \"resid...   \n",
              "4  [{\"domain_start\": 0, \"domain_end\": 110, \"resid...   \n",
              "\n",
              "                                   mmseq_cluster_rep  \n",
              "0  HHHHHHGENLYFQGSLDSPDRPWNPPTFSPALLVVTEGDNATFTCS...  \n",
              "1  HHHHHHGENLYFQGSLDSPDRPWNPPTFSPALLVVTEGDNATFTCS...  \n",
              "2  MAPMLSGLLARLVKLLLGRHGSALHWRAAGAATVLLVIVLLAGSYL...  \n",
              "3  FKVATPYSLYVCPEGQNVTLTCRLLGPVDKGHDVTFYKTWYRSSRG...  \n",
              "4  MEEIVLLFAIVSLARSDQICIGYHANNSTKQVDTIMEKNVTVTHAQ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agab_mmseq.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95773dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "df = pd.read_parquet('data/agab_mmseq.parquet')\n",
        "\n",
        "# Используем GroupShuffleSplit\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Группируем по представителю кластера!\n",
        "splitter = gss.split(df, groups=df['mmseq_cluster_rep'])\n",
        "train_idx, test_idx = next(splitter)\n",
        "\n",
        "train_df = df.iloc[train_idx]\n",
        "test_df = df.iloc[test_idx]\n",
        "\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n",
        "\n",
        "# Проверка на утечки (должно быть 0 пересечений по кластерам)\n",
        "train_clusters = set(train_df['mmseq_cluster_rep'])\n",
        "test_clusters = set(test_df['mmseq_cluster_rep'])\n",
        "print(f\"Пересечение кластеров: {len(train_clusters.intersection(test_clusters))}\") \n",
        "# Если 0 — значит, сплит идеальный."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bio-ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
