{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c265d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8191907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 20 parquet файлов\n",
      "Общий размер данных: (1227083, 11)\n",
      "Колонки: ['dataset', 'heavy_sequence', 'light_sequence', 'scfv', 'affinity_type', 'affinity', 'antigen_sequence', 'confidence', 'nanobody', 'metadata', 'processed_measurement']\n"
     ]
    }
   ],
   "source": [
    "def load_asd_data_with_pandas(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает все parquet файлы из папки asd в один pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        data_path: путь к папке с данными\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: объединенный DataFrame со всеми данными\n",
    "    \"\"\"\n",
    "    # Получаем все parquet файлы из папки\n",
    "    parquet_files = glob.glob(os.path.join(data_path, \"part-*.parquet\"))\n",
    "\n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"Не найдено parquet файлов в папке {data_path}\")\n",
    "\n",
    "    print(f\"Найдено {len(parquet_files)} parquet файлов\")\n",
    "\n",
    "    # Загружаем все файлы в список DataFrame'ов\n",
    "    dataframes = []\n",
    "    for file_path in parquet_files:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Объединяем все DataFrame'ы в один\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    print(f\"Общий размер данных: {combined_df.shape}\")\n",
    "    print(f\"Колонки: {list(combined_df.columns)}\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Загружаем данные\n",
    "agab_df = load_asd_data_with_pandas('./asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73d6396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823251, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_not_nanobody = agab_df['nanobody'] == False\n",
    "is_high_confidence = agab_df['confidence'].isin(['high', 'very_high'])\n",
    "is_scfv = agab_df['scfv'] == True\n",
    "has_both_chains = (\n",
    "    agab_df['light_sequence'].notna() \n",
    "    & agab_df['heavy_sequence'].notna()\n",
    "    & (agab_df['light_sequence'] != '')\n",
    "    & (agab_df['heavy_sequence'] != '')\n",
    ")\n",
    "\n",
    "agab_df = agab_df[is_not_nanobody & is_high_confidence & (is_scfv | has_both_chains)]\n",
    "agab_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd79b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После базовых фильтров: (823251, 11)\n",
      "Распределение по affinity_type до фильтрации по порогам:\n",
      "affinity_type\n",
      "fuzzy                    524346\n",
      "-log KD                  152401\n",
      "alphaseq                 131645\n",
      "kd                         6849\n",
      "log_enrichment             3452\n",
      "bool                       2870\n",
      "ddg                         670\n",
      "elisa_mut_to_wt_ratio       658\n",
      "ic_50                       360\n",
      "Name: count, dtype: int64\n",
      "\n",
      "После фильтрации по порогам аффинитета: (324227, 11)\n",
      "Распределение по affinity_type после фильтрации:\n",
      "affinity_type\n",
      "fuzzy                    172149\n",
      "-log KD                   87733\n",
      "alphaseq                  56068\n",
      "kd                         6744\n",
      "log_enrichment             1016\n",
      "ic_50                       349\n",
      "elisa_mut_to_wt_ratio       168\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (порог, оператор): '<', '>', '=='\n",
    "AFFINITY_THRESHOLDS = {\n",
    "    'fuzzy': ('h', '=='),\n",
    "    'bool': (1, '=='),\n",
    "    'alphaseq': (2, '<'),\n",
    "    '-log KD': (7, '>'),\n",
    "    'kd': (100, '<'),\n",
    "    'delta_g': (-9.5, '<'),\n",
    "    'log_enrichment': (1, '>'),\n",
    "    'elisa_mut_to_wt_ratio': (1, '>'),\n",
    "    'ic_50': (100, '<'),\n",
    "}\n",
    "\n",
    "def apply_affinity_filter(df: pd.DataFrame, thresholds: dict) -> pd.DataFrame:\n",
    "    masks = []\n",
    "    for affinity_type, (threshold, op) in thresholds.items():\n",
    "        type_mask = df['affinity_type'] == affinity_type\n",
    "        if op == '==':\n",
    "            mask = type_mask & (df['affinity'] == threshold)\n",
    "        else:\n",
    "            numeric_affinity = pd.to_numeric(df['affinity'], errors='coerce')\n",
    "            if op == '<':\n",
    "                mask = type_mask & (numeric_affinity < threshold)\n",
    "            else:\n",
    "                mask = type_mask & (numeric_affinity > threshold)\n",
    "        masks.append(mask)\n",
    "\n",
    "    if masks:\n",
    "        combined_mask = masks[0]\n",
    "        for mask in masks[1:]:\n",
    "            combined_mask = combined_mask | mask\n",
    "        return df[combined_mask]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "print(f\"После базовых фильтров: {agab_df.shape}\")\n",
    "print(f\"Распределение по affinity_type до фильтрации по порогам:\")\n",
    "print(agab_df['affinity_type'].value_counts())\n",
    "\n",
    "# Применяем фильтрацию по порогам аффиности\n",
    "agab_df = apply_affinity_filter(agab_df, AFFINITY_THRESHOLDS)\n",
    "\n",
    "print(f\"\\nПосле фильтрации по порогам аффинитета: {agab_df.shape}\")\n",
    "print(f\"Распределение по affinity_type после фильтрации:\")\n",
    "print(agab_df['affinity_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ РАЗЛИЧИЙ В ПОЛЯХ ДЛЯ ДУБЛИКАТОВ ПО ПОСЛЕДОВАТЕЛЬНОСТЯМ (agab_df) ===\n",
      "\n",
      "Всего групп дубликатов: 6052\n",
      "\n",
      "Групп с различиями: 6049 (99.95%)\n",
      "Групп без различий: 3 (0.05%)\n",
      "\n",
      "Строк (записей) с различиями: 12662 (99.95%)\n",
      "Строк (записей) без различий: 6 (0.05%)\n",
      "\n",
      "=== ПОЛЯ, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\n",
      "\n",
      "affinity: 6049 групп (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== АНАЛИЗ РАЗЛИЧИЙ В ПОЛЯХ ДЛЯ ДУБЛИКАТОВ ПО ПОСЛЕДОВАТЕЛЬНОСТЯМ (agab_df) ===\\n\")\n",
    "\n",
    "# Поля для проверки\n",
    "fields = [\n",
    "    \"dataset\",\n",
    "    \"scfv\",\n",
    "    \"affinity_type\",\n",
    "    \"affinity\",\n",
    "    \"confidence\",\n",
    "    \"nanobody\",\n",
    "    \"processed_measurement\",\n",
    "]\n",
    "\n",
    "# --- Поиск групп дубликатов по heavy_sequence + light_sequence + antigen_sequence---\n",
    "# Находим группы, где хотя бы 2 записи с одинаковой парой последовательностей\n",
    "group_cols = [\"heavy_sequence\", \"light_sequence\", \"antigen_sequence\"]\n",
    "grouped = agab_df.groupby(group_cols, sort=False)\n",
    "\n",
    "# Маска строк, которые входят в группы размером > 1\n",
    "dup_mask = grouped[group_cols[0]].transform(\"size\") > 1\n",
    "hl_duplicates = agab_df.loc[dup_mask].copy()\n",
    "\n",
    "# Переиспользуем groupby только на дубликатах\n",
    "dup_groups = hl_duplicates.groupby(group_cols, sort=False)\n",
    "unique_groups_count = dup_groups.ngroups\n",
    "\n",
    "print(f\"Всего групп дубликатов: {unique_groups_count}\\n\")\n",
    "\n",
    "# --- Анализ различий по полям ---\n",
    "\n",
    "# Для каждой группы считаем, сколько уникальных значений в каждом поле\n",
    "# dropna=False, чтобы различия NaN / не-NaN тоже учитывались\n",
    "nunique_per_group = dup_groups[fields].nunique(dropna=False)\n",
    "\n",
    "# Булева матрица: True, если в группе по полю есть различия\n",
    "diff_mask = nunique_per_group > 1\n",
    "\n",
    "# Есть ли вообще различия в группе\n",
    "group_has_diffs = diff_mask.any(axis=1)\n",
    "\n",
    "groups_with_diffs = int(group_has_diffs.sum())\n",
    "groups_identical = int((~group_has_diffs).sum())\n",
    "total = groups_with_diffs + groups_identical if (groups_with_diffs + groups_identical) > 0 else 1\n",
    "\n",
    "print(f\"Групп с различиями: {groups_with_diffs} ({groups_with_diffs / total * 100:.2f}%)\")\n",
    "print(f\"Групп без различий: {groups_identical} ({groups_identical / total * 100:.2f}%)\\n\")\n",
    "\n",
    "# Количество строк (записей) с различиями и без различий\n",
    "rows_with_diffs = group_has_diffs[group_has_diffs].index  # индексы групп с различиями\n",
    "rows_without_diffs = group_has_diffs[~group_has_diffs].index  # индексы групп без различий\n",
    "\n",
    "num_rows_with_diffs = dup_groups.size().loc[rows_with_diffs].sum() if len(rows_with_diffs) > 0 else 0\n",
    "num_rows_without_diffs = dup_groups.size().loc[rows_without_diffs].sum() if len(rows_without_diffs) > 0 else 0\n",
    "rows_total = num_rows_with_diffs + num_rows_without_diffs if (num_rows_with_diffs + num_rows_without_diffs) > 0 else 1\n",
    "\n",
    "print(f\"Строк (записей) с различиями: {num_rows_with_diffs} ({num_rows_with_diffs / rows_total * 100:.2f}%)\")\n",
    "print(f\"Строк (записей) без различий: {num_rows_without_diffs} ({num_rows_without_diffs / rows_total * 100:.2f}%)\\n\")\n",
    "\n",
    "# Считаем, по скольким группам отличается каждое поле\n",
    "field_diffs_counts = diff_mask.sum().sort_values(ascending=False)\n",
    "\n",
    "if groups_with_diffs > 0 and not field_diffs_counts.empty:\n",
    "    print(\"=== ПОЛЯ, КОТОРЫЕ ЧАЩЕ ВСЕГО РАЗЛИЧАЮТСЯ ===\\n\")\n",
    "    for field, count in field_diffs_counts.items():\n",
    "        if count == 0:\n",
    "            continue\n",
    "        print(f\"{field}: {count} групп ({count / groups_with_diffs * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8e602e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ РАЗБРОСА АФФИНИТЕТА В ГРУППАХ ДУБЛИКАТОВ ===\n",
      "\n",
      "Групп с валидными числовыми аффинитетами: 6052\n",
      "Средний разброс аффинитета в группе: 1.2487\n",
      "Медианный разброс: 1.3385\n",
      "Максимальный разброс: 2.8435\n",
      "\n",
      "Типы аффинитета внутри каждой группы совпадают (корректно сравнивать числа).\n",
      "\n",
      "=== ТОП-5 ГРУПП С САМЫМ БОЛЬШИМ РАЗБРОСОМ АФФИНИТЕТА ===\n",
      "\n",
      "Группа 1 (разброс 2.8435):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>affinity_type</th>\n",
       "      <th>affinity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>processed_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279665</th>\n",
       "      <td>alphaseq</td>\n",
       "      <td>alphaseq</td>\n",
       "      <td>1.0284266312344492</td>\n",
       "      <td>high</td>\n",
       "      <td>1.1118588157602758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279666</th>\n",
       "      <td>alphaseq</td>\n",
       "      <td>alphaseq</td>\n",
       "      <td>-1.0209442312708925</td>\n",
       "      <td>high</td>\n",
       "      <td>1.1118588157602758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279667</th>\n",
       "      <td>alphaseq</td>\n",
       "      <td>alphaseq</td>\n",
       "      <td>1.8225332451339469</td>\n",
       "      <td>high</td>\n",
       "      <td>1.1118588157602758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset affinity_type             affinity confidence  \\\n",
       "279665  alphaseq      alphaseq   1.0284266312344492       high   \n",
       "279666  alphaseq      alphaseq  -1.0209442312708925       high   \n",
       "279667  alphaseq      alphaseq   1.8225332451339469       high   \n",
       "\n",
       "       processed_measurement  \n",
       "279665    1.1118588157602758  \n",
       "279666    1.1118588157602758  \n",
       "279667    1.1118588157602758  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Группа 2 (разброс 2.6122):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>affinity_type</th>\n",
       "      <th>affinity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>processed_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714760</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>9.62101875525756</td>\n",
       "      <td>high</td>\n",
       "      <td>8.314932834001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714761</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>7.008846912746411</td>\n",
       "      <td>high</td>\n",
       "      <td>8.314932834001986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset affinity_type           affinity confidence  \\\n",
       "714760    abbd       -log KD   9.62101875525756       high   \n",
       "714761    abbd       -log KD  7.008846912746411       high   \n",
       "\n",
       "       processed_measurement  \n",
       "714760     8.314932834001986  \n",
       "714761     8.314932834001986  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Группа 3 (разброс 2.6086):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>affinity_type</th>\n",
       "      <th>affinity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>processed_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38065</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>9.61745476693648</td>\n",
       "      <td>high</td>\n",
       "      <td>8.313173132795084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38066</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>7.008891498653689</td>\n",
       "      <td>high</td>\n",
       "      <td>8.313173132795084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset affinity_type           affinity confidence  \\\n",
       "38065    abbd       -log KD   9.61745476693648       high   \n",
       "38066    abbd       -log KD  7.008891498653689       high   \n",
       "\n",
       "      processed_measurement  \n",
       "38065     8.313173132795084  \n",
       "38066     8.313173132795084  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Группа 4 (разброс 2.5932):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>affinity_type</th>\n",
       "      <th>affinity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>processed_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1146087</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>9.593389009569856</td>\n",
       "      <td>high</td>\n",
       "      <td>8.296774595329161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146088</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>7.000160181088464</td>\n",
       "      <td>high</td>\n",
       "      <td>8.296774595329161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset affinity_type           affinity confidence  \\\n",
       "1146087    abbd       -log KD  9.593389009569856       high   \n",
       "1146088    abbd       -log KD  7.000160181088464       high   \n",
       "\n",
       "        processed_measurement  \n",
       "1146087     8.296774595329161  \n",
       "1146088     8.296774595329161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Группа 5 (разброс 2.5851):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>affinity_type</th>\n",
       "      <th>affinity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>processed_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1207842</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>9.591688775955054</td>\n",
       "      <td>high</td>\n",
       "      <td>8.299143333258883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207843</th>\n",
       "      <td>abbd</td>\n",
       "      <td>-log KD</td>\n",
       "      <td>7.006597890562709</td>\n",
       "      <td>high</td>\n",
       "      <td>8.299143333258883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset affinity_type           affinity confidence  \\\n",
       "1207842    abbd       -log KD  9.591688775955054       high   \n",
       "1207843    abbd       -log KD  7.006597890562709       high   \n",
       "\n",
       "        processed_measurement  \n",
       "1207842     8.299143333258883  \n",
       "1207843     8.299143333258883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== АНАЛИЗ РАЗБРОСА АФФИНИТЕТА В ГРУППАХ ДУБЛИКАТОВ ===\\n\")\n",
    "\n",
    "# Работаем с копией дубликатов\n",
    "analysis_df = hl_duplicates.copy()\n",
    "\n",
    "# Преобразуем аффинитет в числа, нечисловые значения станут NaN\n",
    "analysis_df['affinity_numeric'] = pd.to_numeric(analysis_df['affinity'], errors='coerce')\n",
    "\n",
    "# Группируем\n",
    "grouped_analysis = analysis_df.groupby(group_cols, sort=False)\n",
    "\n",
    "# Считаем размах (max - min) и проверяем единственность типа аффинитета\n",
    "agg_funcs = {\n",
    "    'affinity_numeric': lambda x: x.max() - x.min(),\n",
    "    'affinity_type': 'nunique'\n",
    "}\n",
    "\n",
    "group_stats = grouped_analysis.agg(agg_funcs)\n",
    "group_stats.columns = ['affinity_range', 'affinity_type_count']\n",
    "\n",
    "# Фильтруем группы, где affinity_numeric удалось посчитать (не NaN)\n",
    "valid_stats = group_stats.dropna(subset=['affinity_range'])\n",
    "\n",
    "print(f\"Групп с валидными числовыми аффинитетами: {len(valid_stats)}\")\n",
    "print(f\"Средний разброс аффинитета в группе: {valid_stats['affinity_range'].mean():.4f}\")\n",
    "print(f\"Медианный разброс: {valid_stats['affinity_range'].median():.4f}\")\n",
    "print(f\"Максимальный разброс: {valid_stats['affinity_range'].max():.4f}\\n\")\n",
    "\n",
    "# Проверка на разные типы аффинитета в одной группе\n",
    "mixed_types = valid_stats[valid_stats['affinity_type_count'] > 1]\n",
    "if not mixed_types.empty:\n",
    "    print(f\"ВНИМАНИЕ: В {len(mixed_types)} группах смешаны разные типы аффинитета (сравнение может быть некорректным).\")\n",
    "else:\n",
    "    print(\"Типы аффинитета внутри каждой группы совпадают (корректно сравнивать числа).\\n\")\n",
    "\n",
    "# Топ-5 групп с самым большим разбросом\n",
    "print(\"=== ТОП-5 ГРУПП С САМЫМ БОЛЬШИМ РАЗБРОСОМ АФФИНИТЕТА ===\")\n",
    "top_diff_groups = valid_stats.nlargest(5, 'affinity_range')\n",
    "\n",
    "for idx, (indices, row) in enumerate(top_diff_groups.iterrows()):\n",
    "    heavy, light, antigen = indices\n",
    "    print(f\"\\nГруппа {idx+1} (разброс {row['affinity_range']:.4f}):\")\n",
    "    # Получаем строки этой группы\n",
    "    group_rows = analysis_df[\n",
    "        (analysis_df['heavy_sequence'] == heavy) & \n",
    "        (analysis_df['light_sequence'] == light) &\n",
    "        (analysis_df['antigen_sequence'] == antigen)\n",
    "    ]\n",
    "    display(group_rows[['dataset', 'affinity_type', 'affinity', 'confidence', 'processed_measurement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2080d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер до удаления дубликатов: (324227, 11)\n",
      "Размер после удаления дубликатов: (317611, 11)\n"
     ]
    }
   ],
   "source": [
    "# Удаляем дубликаты по heavy_sequence + light_sequence + antigen_sequence\n",
    "# Оставляем первую запись из каждой группы (affinity отличается, но это не важно)\n",
    "\n",
    "print(f\"Размер до удаления дубликатов: {agab_df.shape}\")\n",
    "\n",
    "agab_df = agab_df.drop_duplicates(\n",
    "    subset=['heavy_sequence', 'light_sequence', 'antigen_sequence'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "print(f\"Размер после удаления дубликатов: {agab_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем датафрейм для использования в других ноутбуках\n",
    "output_path = 'agab_filtered.parquet'\n",
    "agab_df.to_parquet(output_path, index=False, engine='pyarrow')\n",
    "print(f\"Отфильтрованные данные сохранены в {output_path}\")\n",
    "print(f\"Размер сохраненных данных: {agab_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antibody_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
